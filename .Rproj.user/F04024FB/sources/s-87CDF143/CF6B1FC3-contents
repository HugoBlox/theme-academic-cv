---
title: "Disney"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r cars}
library(tidyverse)
library(lubridate)
library(corrplot)
library(caret)
library(skimr)
library(ModelMetrics)
library(janitor)
library(broom)

```



```{r pressure, echo=FALSE}
setwd('/Users/mikaylaedwards/academic1/content/post')
meta<-read_csv("metadata.csv")
merged_rides<- read_csv("merged_rides_.csv")
merged_rides$datetime <- as_datetime(merged_rides$datetime)
```


```{r}
skim(merged_rides)
```
We have 7 columns total:a datetime index and the wait times for 6 rides. No missing data 
```{r}
merged_rides %>% gather(key="ride",value="wait_time",-datetime) %>% 
ggplot(aes(ride, wait_time, group = ride)) +
  geom_boxplot(colour = "black", fill = "#56B4E9",notch = T) +
  ylab("Wait time")

```
This shows the distribution of wait times by ride. We see, for example, that Seven Dwarfs has the highest median wait time, while Spaceship Earth has the lowest.
```{r}
# merged_rides<-merged_rides %>% filter(
#   seven_dwarfs<150,
#   rockin_rollercoaster<140,
#   soarin<130,
#   space_earth<50,
#   splash_mountain<140,
#   toy_story_mania<140
# )
```

```{r}
rides1<-merged_rides%>%
  mutate(hour=hour(datetime),
         date=date(datetime)) %>%
  group_by(hour,date)%>% filter(hour<21 & hour>8) %>%
  summarize_at(
    vars(toy_story_mania:soarin),
    ~mean(.,na.rm =TRUE)
  )
head(rides1)
```

```{r}
```

```{r}
rides1 %>% 
select_if(is.numeric) %>% 
cor() %>% 
corrplot(type = "upper", order = "hclust",addCoef.col = "black",
         tl.col = "black", tl.srt = 45)
```

```{r}
avg_by_month <- rides1 %>%
  mutate(month = month(date, label = TRUE)) %>%
  group_by(month) %>%
  summarize_at(vars(toy_story_mania:soarin),
  ~ mean(., na.rm = TRUE))
```

```{r}
avg_by_month %>% gather(key="ride",value="avg_wait",-month,) %>% 
ggplot(aes(x=month,y=avg_wait,color=ride)) + geom_line(aes(group = ride)) +
geom_point() + xlab("Month")
```



```{r}
##Looking at MK
rides1 %>%
  keep(is.numeric) %>% 
  gather(key="ride",value="wait",-hour) %>% 
ggplot(aes(x = wait, fill = as.factor(ride))) + 
  geom_density(alpha = .3)+xlim(5,220)+ labs(title="Wait Time Dist.")+scale_fill_discrete(name="Ride")


```

```{r}
rides2<-rides1 %>% select(seven_dwarfs,rockin_rollercoaster,-date)%>% gather(key="ride",value="avg_wait_byhour",-hour) 
```

```{r}
rides2%>% ggplot(aes(x=as.factor(hour),y=avg_wait_byhour,fill=ride))+
geom_boxplot(outlier.shape=NA, position = position_dodge(.9))+xlab("Hour")+ylim(0,200)
```

```{r}
##selecting features to explore
meta1<-meta %>% select(DATE, contains('event'),-contains('eventN'),contains('HOLIDAY'),-contains('DAYS'),-contains('STREAK'),-HOLIDAYJ)

meta1$date<-as.character(meta1$DATE)
meta1$date <-ymd(mdy(meta1$date))
meta1$DATE<-NULL
meta1<-meta1 %>% clean_names()  
meta1$holidayn<-fct_explicit_na(meta1$holidayn, "no holiday")
kabble(head(meta1))
```

```{r}
library(forcats)
meta1$holidayn<-fct_explicit_na(meta1$holidayn, "no holiday")
head(meta1)
```

```{r}
mrides<-rides1 %>% 
merge(meta1,by="date")%>% 
arrange(date,hour) %>% mutate(
  hour=as.factor(hour),  
  month=as.factor(month(date)),
  year=as.factor(year(date)))   
           
head(mrides)

```



```{r}
mrides %>% group_by(holiday,hour) %>% summarize_at(
  vars(toy_story_mania:soarin),
  ~mean(.)
) %>% 
  gather(key="ride",value="wait_time",toy_story_mania:soarin) %>% 
  ggplot(aes(x=hour,y=wait_time,color=as.logical(holiday)))+geom_line(aes(group=holiday))+facet_wrap(~ride,scales = "free_x")
```

Build model for each ride. 
```{r}

```


```{r}
rides_nest<-mrides %>% gather(key="ride",value="wait_time",toy_story_mania:soarin)%>%  group_by(ride) %>% nest()
head(rides_nest)
  
```


```{r}
rides_nest$data[[1]]
```

```{r}
##building model for each ride
nest_model<-rides_nest %>% 
  mutate(model=map(data,~lm(formula =wait_time~.,data=.x)))
         
  coef<-nest_model %>% 
    mutate(coef=map(model,~tidy(.x))) %>% 
      unnest(coef)
```


```{r}
coef %>% select(ride:estimate) %>% filter(term!='(Intercept)') %>%  group_by(ride) %>% top_n(5,estimate) %>%  ggplot(aes(x=term,y=estimate))+geom_bar(stat="identity") + facet_wrap(~ride,scales="free_y") +
  coord_flip()



```

```{r}
head(mrides)
mrides %>% 
  filter(stringr::str_detect(holidayn, "nye|cme|ind") ) %>% gather(key="ride",value="wait_time",toy_story_mania:soarin) %>% group_by(ride,hour,holidayn) %>% summarize(avg_wait=mean(wait_time)) %>% 
 ggplot(aes(x=hour,y=avg_wait,group=holidayn,color=holidayn))+geom_line(aes(group=holidayn))+facet_wrap(~ride,scales="free_y","free_x")
        
# ggplot(aes(x=hour,y=wait_time, fill=holidayn))+geom_col(position=position_dodge())+
#   facet_wrap(~ride,scales = "free_x")
```

NYE seems to have the highest wait times for all rides. This is consistent with the coefficient importance results shown above. For some rides,the wait time difference is more significant(e.g.soarin).This is also reflected in the coefficient estimate above. For splash mountain, however, independence day (July 4th) times are also very high. This makes sense given that it's a water ride whose popularity we would expect to be highest in summer. 



```{r}
model_perf<-nest_model %>% 
  mutate(
    fit=map(model,~glance(.x)),
    augmented=map(model,~augment(.x))
  )

```

```{r}

aug<-model_perf %>% 
  unnest(augmented)
##calc mae for each ride model
aug_mae<-aug %>% group_by(ride) %>% 
  transmute(mae=mae(wait_time,.fitted)) %>% distinct()
```

```{r}
 fit<-model_perf%>% 
  unnest(fit)

##calc mae

```

To get an idea of model performance, let's compare our predictions vs actual wait time on NYE 2015. 

```{r}
ggplot(aug,aes(wait_time,.fitted))+geom_smooth()+geom_abline(intercept=0,slope=1)+facet_wrap(~ride)
```



XGboost
```{r}
set.seed(1234)

mrides_long<-mrides %>% gather(key="ride",value="wait_time",toy_story_mania:soarin) 

mrides_long<-mrides_long%>% mutate_if(is.factor,as.character) 

mrides_long_numeric<-mrides_long %>% select(-date) %>% select_if(is.numeric)
##Remove target


# get vector of training labels
waitLabels <- mrides_long_numeric %>% mutate(wait_time=as.numeric(wait_time)) %>% select(wait_time)
waitLabels<-as.vector(waitLabels$wait_time)

##remove outcome variable
mrides_long_numeric<-mrides_long_numeric %>% select(-wait_time)
##one-hot for categorical vars (holidayn,hour,month)--creates matrix of 1/0. e.g. is 1 if day is that holiday.
holiday_name <- model.matrix(~holidayn-1, mrides_long)

hour_mat <- model.matrix(~hour-1, mrides_long)
mon_mat <- model.matrix(~month-1, mrides_long)
year_mat <- model.matrix(~year-1, mrides_long)
ride_mat<- model.matrix(~ride-1, mrides_long)

mrides_long<- cbind(mrides_long_numeric, holiday_name,hour_mat,mon_mat,year_mat,ride_mat) 

#convert to numeric
mrides_long<-mrides_long %>% mutate_if(is.integer,as.numeric)
 

mrides_matrix <- data.matrix(mrides_long)

```



```{r}
# get the 70/30 training test split
numberOfTrainingSamples <- round(length(waitLabels) * .7)
# training data
train_data <- mrides_matrix[1:numberOfTrainingSamples,]
train_labels <- waitLabels[1:numberOfTrainingSamples]

# testing data
test_data <- mrides_matrix[-(1:numberOfTrainingSamples),]
test_labels <- waitLabels[-(1:numberOfTrainingSamples)]
```

```{r}
library(xgboost)
# put testing & training data into seperate Dmatrix objects

dtrain <- xgb.DMatrix(data = train_data, label= train_labels)
dtest <- xgb.DMatrix(data = test_data, label= test_labels)
```

```{r}
# train a model using training data
xgb <- xgboost(data = dtrain,   
                nrounds = 200,print_every_n = 50, early_stop_round = 20, verbose = 1)

```

```{r}
#model prediction
xgbpred <- predict (xgb,dtest)
xgb_mae<- mae(test_labels, xgbpred)
df<-data.frame("xgb",xgb_mae)
df<-rbind(aug_mae,df)
aug_mae%>% ggplot(aes(x=ride,y=mae))+geom_col()
```

```{r}
## Plot the feature importance
importance_matrix <- xgb.importance(colnames(dtrain), model = xgb)
xgb.plot.importance(importance_matrix = importance_matrix[1:20])
```

```{r}
residuals = y_test - predicted
RMSE = sqrt(mean(residuals^2))
cat('The root mean square error of the test data is ', round(RMSE,3),'\n')
The root mean square error of the test data is 2.856
y_test_mean = mean(y_test)
# Calculate total sum of squares
tss =  sum((y_test - y_test_mean)^2 )
# Calculate residual sum of squares
rss =  sum(residuals^2)
# Calculate R-squared
rsq  =  1 - (rss/tss)
cat('The R-square of the test data is ', round(rsq,3), '\n')
The R-square of the test data is 0.972
Plotting actual vs predicted
options(repr.plot.width=8, repr.plot.height=4)
my_data = as.data.frame(cbind(predicted = predicted,
                            observed = y_test))
# Plot predictions vs test data
ggplot(my_data,aes(predicted, observed)) + geom_point(color = "darkred", alpha = 0.5) + 
    geom_smooth(method=lm)+ ggtitle('Linear Regression ') + ggtitle("Extreme Gradient Boosting: Prediction vs Test Data") +
      xlab("Predecited Power Output ") + ylab("Observed Power Output") 
```



