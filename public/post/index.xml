<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Mikayla Edwards</title>
    <link>/post/</link>
    <description>Recent content in Posts on Mikayla Edwards</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 21 Sep 2019 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/post/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Wait Times Shiny App &#43; More Visuals</title>
      <link>/post/wait-times-revisited/</link>
      <pubDate>Sat, 21 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/wait-times-revisited/</guid>
      <description>Shiny App##shiny code ui &amp;lt;- fluidPage(sidebarLayout(sidebarPanel(selectInput(&amp;quot;ride&amp;quot;,&amp;quot;Ride&amp;quot;,choices = unique(files$ride),multiple = TRUE,selected =c(&amp;quot;flight_of_passage&amp;quot;,&amp;quot;7_dwarfs_train&amp;quot;,&amp;quot;slinky_dog&amp;quot;)),dateInput(&amp;#39;date1&amp;#39;,label = &amp;#39;Date input 1: yyyy-mm-dd&amp;#39;,value = ymd(&amp;quot;2019-07-04&amp;quot;)),dateInput(&amp;#39;date2&amp;#39;,label = &amp;#39;Date input 2: yyyy-mm-dd&amp;#39;,value = ymd(&amp;quot;2019-07-05&amp;quot;))),mainPanel(# Replace the `plotOutput()` with the plotly versionplotlyOutput(&amp;quot;plot&amp;quot;))))# Define the server logicserver &amp;lt;- function(input, output) {# Replace the `renderPlot()` with the plotly versionoutput$plot &amp;lt;- renderPlotly({# Convert the existing ggplot2 to a plotly plotggplotly({data &amp;lt;- subset(files,ride %in% input$ride &amp;amp;date %in% c(input$date1, input$date2))p &amp;lt;- ggplot(data, aes(x=datetime,y=time,color=ride))+geom_line()+facet_grid(~date,scales=&amp;quot;free_x&amp;quot;)+ggtitle(&amp;quot;Compare Wait Times&amp;quot;)+scale_color_brewer(palette = &amp;quot;Dark2&amp;quot;)})})}shinyApp(ui = ui, server = server)The app below allows for comparison of wait times on two different dates.</description>
    </item>
    
    <item>
      <title>Grand Floridian Hotel Reviews Sentiment Analysis &amp; NLP</title>
      <link>/post/grand-floridian-hotel-reviews/</link>
      <pubDate>Sun, 11 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/grand-floridian-hotel-reviews/</guid>
      <description>Grand Floridian Hotel Reviews: Sentiment Analysis and NLPThe data for this analysis was obtained from the reviews posted on TripAdvisor. I used RSelenium and rvest to extract the data from the first 3000 dynamic web-pages on the TripAdvisor site, which was 2,350 reviews in total. The code used to do this is published on my GitHub here
Here, I load the the Rda file I saved from that extraction.</description>
    </item>
    
    <item>
      <title>DVC Points Chart Analysis(Part 2)</title>
      <link>/post/dvc-points-chart-analysis-part-2/</link>
      <pubDate>Wed, 07 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/dvc-points-chart-analysis-part-2/</guid>
      <description>DVC AnalysisIn this post, I will expand on my analysis from part 1. Here, I will merge the points charts datasets I created for Bay Lake Tower (BLT) and The Beach Club (BC). By wrangling the charts into a “tidy” data structure, we can easily produce visualizations and insights comparing the two resorts.
library(tidyverse)library(lubridate)library(plotly)bc&amp;lt;-readRDS(&amp;quot;BC2020.rds&amp;quot;)blt&amp;lt;-readRDS(&amp;quot;BLT2020.rds&amp;quot;)comp&amp;lt;-bind_rows(bc,blt)comp$resort&amp;lt;-as.factor(comp$resort)head(comp)## room season weekday points resort view## 1 Studio ADVENTURE Sun_Th 15 Beach Club &amp;lt;NA&amp;gt;## 2 1-Bedroom ADVENTURE Sun_Th 27 Beach Club &amp;lt;NA&amp;gt;## 3 2-Bedroom ADVENTURE Sun_Th 37 Beach Club &amp;lt;NA&amp;gt;## 4 Studio CHOICE Sun_Th 15 Beach Club &amp;lt;NA&amp;gt;## 5 1-Bedroom CHOICE Sun_Th 29 Beach Club &amp;lt;NA&amp;gt;## 6 2-Bedroom CHOICE Sun_Th 38 Beach Club &amp;lt;NA&amp;gt;Below I filter out 3 bedrooms, as Beach Club does not have this room type, and plot the average points required for each season, room type, and resort.</description>
    </item>
    
    <item>
      <title>How to Save Time Using the Kaggle API from RStudio</title>
      <link>/post/test/</link>
      <pubDate>Thu, 01 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/test/</guid>
      <description>Although there are many resources explaining how to use the Kaggle API in Python, I could not find much information about using it from Rstudio. Therefore, in this post I will explain how to use the kaggle API (via kaggler) to search for and download datasets available on the site.
Installing packages#devtools::install_github(&amp;quot;mkearney/kaggler&amp;quot;)library(kaggler)library(tidyverse)library(kableExtra)library(knitr)library(plotly)library(tableHTML)library(htmlTable)library(xtable)Next we need to run kgl_auth(username=“yourusername”,key=“yourpassword”) to establish a connection to the API.</description>
    </item>
    
    <item>
      <title>Sales Forecasting Anomaly Detection</title>
      <link>/post/sales-forecasting-anomaly-detection/</link>
      <pubDate>Thu, 01 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/sales-forecasting-anomaly-detection/</guid>
      <description>The data for this analysis comes my previous call to the Kaggle API (see How to Save Time Using The Kaggle API)
From that pipeline, I have a vector of filenames that I want to read in and save as a dataframe. Instead of copying and pasting many calls to read_csv, I will use the “purrr” family to map functions to the filenames. Using str_extract, I will create a vector of data frame names.</description>
    </item>
    
    <item>
      <title>Predicting Wait Times at Walt Disney World: LM vs XGboost</title>
      <link>/post/wait-times-at-walt-disney-world/</link>
      <pubDate>Mon, 22 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/wait-times-at-walt-disney-world/</guid>
      <description>The data used for this analysis was originally published by Touring Plans.
I used the data for six rides: two from the Magic Kingdom (Seven Dwarfs Mine Train &amp;amp; Splash Mountain), two from Hollywood Studios (Toy Story Mania &amp;amp; The Rockin Rollercoaster), and two from Epcot (Soarin &amp;amp; Spaceship Earth).
library(tidyverse)library(lubridate)library(skimr)library(ModelMetrics)library(janitor)library(broom)library(forcats)library(kableExtra)library(stringr)There was a separate csv file for each ride. I originally merged &amp;amp; cleaned this data using Python, which can be found here.</description>
    </item>
    
    <item>
      <title>Fast Food Nutrition Analysis</title>
      <link>/post/fast-food-nutrition-analysis/</link>
      <pubDate>Wed, 10 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/fast-food-nutrition-analysis/</guid>
      <description>library(tidyverse)library(ggthemes)library(tidytext)library(purrr)library(stats)library(corrr)library(RColorBrewer)R Markdown## # A tibble: 6 x 18## X1 restaurant item calories cal_fat total_fat sat_fat trans_fat## &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;## 1 1 Mcdonalds Arti~ 380 60 7 2 0 ## 2 2 Mcdonalds Sing~ 840 410 45 17 1.5## 3 3 Mcdonalds Doub~ 1130 600 67 27 3 ## 4 4 Mcdonalds Gril~ 750 280 31 10 0.</description>
    </item>
    
    <item>
      <title>DVC Points Chart Analysis (Part 1)</title>
      <link>/post/dvc-points-chart-analysis-part-1/</link>
      <pubDate>Sat, 14 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/dvc-points-chart-analysis-part-1/</guid>
      <description>In this series of posts, I will analyze and compare the 2020 points charts for Bay Lake Tower and the The Beach Club. Html versions of the charts (used here) can be found on DVC Request
This post (part 1) will detail the code to extract the points charts from the html table format they are published in. I will use the rvest package as well as unpivotr to convert the data into a tabular dataframe.</description>
    </item>
    
  </channel>
</rss>