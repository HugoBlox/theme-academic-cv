<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Mikayla Edwards</title>
    <link>/post/</link>
    <description>Recent content in Posts on Mikayla Edwards</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 07 Dec 2019 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/post/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Comparing Recommder System Methods: recommenderlab and sparklyr</title>
      <link>/post/comparing-recommder-system-methods-recommenderlab-and-sparklyr/</link>
      <pubDate>Sat, 07 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/comparing-recommder-system-methods-recommenderlab-and-sparklyr/</guid>
      <description>I will use the Yelp dataset to compare recommendation system implementations in recommenderlab and sparklyr.Data can be found on Yelp here
The Yelp datasets are stored in JSON file format and are quite large. Using high performance methods will be important. Below I write a function to transform the JSON files into dataframes. I use the jsonlite package to efficiently stream in and flatten the files.</description>
    </item>
    
    <item>
      <title>Wait Times Shiny App &#43; More Visuals</title>
      <link>/post/wait-times-revisited/</link>
      <pubDate>Sat, 21 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/wait-times-revisited/</guid>
      <description>Shiny App##shiny code ui &amp;lt;- fluidPage(sidebarLayout(sidebarPanel(selectInput(&amp;quot;ride&amp;quot;,&amp;quot;Ride&amp;quot;,choices = unique(files$ride),multiple = TRUE,selected =c(&amp;quot;flight_of_passage&amp;quot;,&amp;quot;7_dwarfs_train&amp;quot;,&amp;quot;slinky_dog&amp;quot;)),dateInput(&amp;#39;date1&amp;#39;,label = &amp;#39;Date input 1: yyyy-mm-dd&amp;#39;,value = ymd(&amp;quot;2019-07-04&amp;quot;)),dateInput(&amp;#39;date2&amp;#39;,label = &amp;#39;Date input 2: yyyy-mm-dd&amp;#39;,value = ymd(&amp;quot;2019-07-05&amp;quot;))),mainPanel(# Replace the `plotOutput()` with the plotly versionplotlyOutput(&amp;quot;plot&amp;quot;))))# Define the server logicserver &amp;lt;- function(input, output) {# Replace the `renderPlot()` with the plotly versionoutput$plot &amp;lt;- renderPlotly({# Convert the existing ggplot2 to a plotly plotggplotly({data &amp;lt;- subset(files,ride %in% input$ride &amp;amp;date %in% c(input$date1, input$date2))p &amp;lt;- ggplot(data, aes(x=datetime,y=time,color=ride))+geom_line()+facet_grid(~date,scales=&amp;quot;free_x&amp;quot;)+ggtitle(&amp;quot;Compare Wait Times&amp;quot;)+scale_color_brewer(palette = &amp;quot;Dark2&amp;quot;)})})}shinyApp(ui = ui, server = server)The app below allows for comparison of wait times on two different dates.</description>
    </item>
    
    <item>
      <title>Grand Floridian Hotel Reviews Sentiment Analysis &amp; NLP</title>
      <link>/post/grand-floridian-hotel-reviews/</link>
      <pubDate>Sun, 11 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/grand-floridian-hotel-reviews/</guid>
      <description>Grand Floridian Hotel Reviews: Sentiment Analysis and NLPlibrary(tidyverse)library(zoo)library(knitr)library(tidytext)library(SnowballC)library(keras)library(kableExtra)This is the raw version of the reviews data: it has the text content of the review, the star rating (1-5), and the date of stay (month/year).
It requires a bit of cleaning to get in the form we want.
#rename &amp;amp; change variable typerdf &amp;lt;- rdf %&amp;gt;% rename(stay_date = id_date,review = reviews) %&amp;gt;%mutate_at(vars(stay_date, review),~ as.</description>
    </item>
    
    <item>
      <title>DVC Points Chart Analysis(Part 2)</title>
      <link>/post/dvc-points-chart-analysis-part-2/</link>
      <pubDate>Wed, 07 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/dvc-points-chart-analysis-part-2/</guid>
      <description>DVC AnalysisIn this post, I will expand on my analysis from part 1. Here, I will merge the points charts datasets I created for Bay Lake Tower (BLT) and The Beach Club (BC). By wrangling the charts into a “tidy” data structure, we can easily produce visualizations and insights comparing the two resorts.
library(tidyverse)library(lubridate)library(plotly)bc&amp;lt;-readRDS(&amp;quot;BC2020.rds&amp;quot;)blt&amp;lt;-readRDS(&amp;quot;BLT2020.rds&amp;quot;)comp&amp;lt;-bind_rows(bc,blt)comp$resort&amp;lt;-as.factor(comp$resort)head(comp)## room season weekday points resort view## 1 Studio ADVENTURE Sun_Th 15 Beach Club &amp;lt;NA&amp;gt;## 2 1-Bedroom ADVENTURE Sun_Th 27 Beach Club &amp;lt;NA&amp;gt;## 3 2-Bedroom ADVENTURE Sun_Th 37 Beach Club &amp;lt;NA&amp;gt;## 4 Studio CHOICE Sun_Th 15 Beach Club &amp;lt;NA&amp;gt;## 5 1-Bedroom CHOICE Sun_Th 29 Beach Club &amp;lt;NA&amp;gt;## 6 2-Bedroom CHOICE Sun_Th 38 Beach Club &amp;lt;NA&amp;gt;Below I filter out 3 bedrooms, as Beach Club does not have this room type, and plot the average points required for each season, room type, and resort.</description>
    </item>
    
    <item>
      <title>How to Save Time Using the Kaggle API from RStudio</title>
      <link>/post/test/</link>
      <pubDate>Thu, 01 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/test/</guid>
      <description>Although there are many resources explaining how to use the Kaggle API in Python, I could not find much information about using it from Rstudio. Therefore, in this post I will explain how to use the kaggle API (via kaggler) to search for and download datasets available on the site.
Installing packages#devtools::install_github(&amp;quot;mkearney/kaggler&amp;quot;)library(kaggler)library(tidyverse)library(kableExtra)library(knitr)library(plotly)library(tableHTML)library(htmlTable)library(xtable)Next we need to run kgl_auth(username=“yourusername”,key=“yourpassword”) to establish a connection to the API.</description>
    </item>
    
    <item>
      <title>Sales Forecasting Anomaly Detection</title>
      <link>/post/sales-forecasting-anomaly-detection/</link>
      <pubDate>Thu, 01 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/sales-forecasting-anomaly-detection/</guid>
      <description>The data for this analysis comes my previous call to the Kaggle API (see How to Save Time Using The Kaggle API)
From that pipeline, I have a vector of filenames that I want to read in and save as a dataframe. Instead of copying and pasting many calls to read_csv, I will use the “purrr” family to map functions to the filenames. Using str_extract, I will create a vector of data frame names.</description>
    </item>
    
    <item>
      <title>Predicting Wait Times at Walt Disney World: LM vs XGboost</title>
      <link>/post/wait-times-at-walt-disney-world/</link>
      <pubDate>Mon, 22 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/wait-times-at-walt-disney-world/</guid>
      <description>The data used for this analysis was originally published by Touring Plans.
I used the data for six rides: two from the Magic Kingdom (Seven Dwarfs Mine Train &amp;amp; Splash Mountain), two from Hollywood Studios (Toy Story Mania &amp;amp; The Rockin Rollercoaster), and two from Epcot (Soarin &amp;amp; Spaceship Earth).
library(tidyverse)library(lubridate)library(skimr)library(ModelMetrics)library(janitor)library(broom)library(forcats)library(kableExtra)library(stringr)There was a separate csv file for each ride. I originally merged &amp;amp; cleaned this data using Python, which can be found here.</description>
    </item>
    
    <item>
      <title>Fast Food Nutrition Analysis</title>
      <link>/post/fast-food-nutrition-analysis/</link>
      <pubDate>Wed, 10 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/fast-food-nutrition-analysis/</guid>
      <description>library(tidyverse)library(ggthemes)library(tidytext)library(purrr)library(stats)library(corrr)library(RColorBrewer)R Markdown## # A tibble: 6 x 18## X1 restaurant item calories cal_fat total_fat sat_fat trans_fat## &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;## 1 1 Mcdonalds Arti~ 380 60 7 2 0 ## 2 2 Mcdonalds Sing~ 840 410 45 17 1.5## 3 3 Mcdonalds Doub~ 1130 600 67 27 3 ## 4 4 Mcdonalds Gril~ 750 280 31 10 0.</description>
    </item>
    
    <item>
      <title>DVC Points Chart Analysis (Part 1)</title>
      <link>/post/dvc-points-chart-analysis-part-1/</link>
      <pubDate>Sat, 14 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/dvc-points-chart-analysis-part-1/</guid>
      <description>In this series of posts, I will analyze and compare the 2020 points charts for Bay Lake Tower and the The Beach Club. Html versions of the charts (used here) can be found on DVC Request
This post (part 1) will detail the code to extract the points charts from the html table format they are published in. I will use the rvest package as well as unpivotr to convert the data into a tabular dataframe.</description>
    </item>
    
    <item>
      <title></title>
      <link>/post/airbnb/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/post/airbnb/</guid>
      <description>In this analysis, I will try different feature engineering and modeling approaches to predict the destination a user will book on AirBnb. Because there a multiple country destinations represented in the dataset, this is a multi-class classification problem.
I was interested in this AirBnb problem because it presents an unbalanced class-representation problem: a large majority of the outcome variable is concentrated in two classes, with NDF and the US representing 58% and 29% respectively.</description>
    </item>
    
  </channel>
</rss>