@inproceedings{wu2023notonly,
 abstract = {The duality of content and style is inherent to the nature of art. For humans, these two elements are clearly different: content refers to the objects and concepts in the piece of art, and style to the way it is expressed. This duality poses an important challenge for computer vision. The visual appearance of objects and concepts is modulated by the style that may reflect the authorâ€™s emotions, social trends, artistic movement, etc., and their deep comprehension undoubtfully requires to handle both. A promising step towards a general paradigm for art analysis is to disentangle content and style, whereas relying on human annotations to cull a single aspect of artworks has limitations in learning semantic concepts and the visual appearance of paintings. We thus present GOYA, a method that distills the artistic knowledge captured in a recent generative model to disentangle content and style. Experiments show that synthetically generated images sufficiently serve as a proxy of the real distribution of artworks, allowing GOYA to separately represent the two elements of art while keeping more information than existing methods.},
 author = {Yankun Wu and Yuta Nakashima and Noa Garcia},
 booktitle = {Proc.~ 2023 ACM International Conference on Multimedia Retrieval (ICMR)},
 doi = {https://doi.org/10.1145/3591106.3592262},
 month = {6},
 pages = {199--208},
 title = {Not only generative art: Stable diffusion for content-style disentanglement in art analysis},
 url = {https://dl.acm.org/doi/abs/10.1145/3591106.3592262},
 year = {2023}
}

