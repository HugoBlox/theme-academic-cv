@article{Tejero-De-Pablos2018,
 abstract = {Automatically generating a summary of a sports video poses the challenge of detecting interesting moments, or highlights, of a game. Traditional sports video summarization methods leverage editing conventions of broadcast sports video that facilitate the extraction of high-level semantics. However, user-generated videos are not edited and, thus, traditional methods are not suitable to generate a summary. In order to solve this problem, this paper proposes a novel video summarization method that uses players' actions as a cue to determine the highlights of the original video. A deep neural-network-based approach is used to extract two types of action-related features and to classify video segments into interesting or uninteresting parts. The proposed method can be applied to any sports in which games consist of a succession of actions. Especially, this paper considers the case of Kendo (Japanese fencing) as an example of a sport to evaluate the proposed method. The method is trained using Kendo videos with ground truth labels that indicate the video highlights. The labels are provided by annotators possessing a different experience with respect to Kendo to demonstrate how the proposed method adapts to different needs. The performance of the proposed method is compared with several combinations of different features, and the results show that it outperforms previous summarization methods.},
 archiveprefix = {arXiv},
 arxivid = {1709.08421},
 author = {Tejero-De-Pablos, Antonio and Nakashima, Yuta and Sato, Tomokazu and Yokoya, Naokazu and Linna, Marko and Rahtu, Esa},
 doi = {10.1109/TMM.2018.2794265},
 eprint = {1709.08421},
 issn = {1520-9210},
 journal = {IEEE Transactions on Multimedia},
 keywords = {3D convolutional neural networks,Cameras,Feature extraction,Games,Hidden Markov models,Japanese fencing,Kendo videos,Semantics,Sports video summarization,Three-dimensional displays,action recognition,action-related features,deep action recognition features,deep learning,deep neural-network-based approach,feature extraction,high-level semantics,image segmentation,interesting parts,long short-term memory,neural nets,player action,sport,uninteresting parts,user-generated sport video summarization method,user-generated video,video highlights,video segments,video signal processing},
 mendeley-tags = {3D convolutional neural networks,Cameras,Feature extraction,Games,Hidden Markov models,Japanese fencing,Kendo videos,Semantics,Sports video summarization,Three-dimensional displays,action recognition,action-related features,deep action recognition features,deep learning,deep neural-network-based approach,feature extraction,high-level semantics,image segmentation,interesting parts,long short-term memory,neural nets,player action,sport,uninteresting parts,user-generated sport video summarization method,user-generated video,video highlights,video segments,video signal processing},
 month = {aug},
 number = {8},
 pages = {2000--2011},
 publisher = {Institute of Electrical and Electronics Engineers Inc.},
 title = {Summarization of user-generated sports video by using deep action recognition features},
 url = {https://ieeexplore.ieee.org/document/8259321},
 volume = {20},
 year = {2018}
}
