@inproceedings{Garcia2019a,
 abstract = {Â© 2019 Association for Computing Machinery. Automatic art analysis aims to classify and retrieve artistic representations from a collection of images by using computer vision and machine learning techniques. In this work, we propose to enhance visual representations from neural networks with contextual artistic information. Whereas visual representations are able to capture information about the content and the style of an artwork, our proposed context-aware embeddings additionally encode relationships between different artistic attributes, such as author, school, or historical period. We design two different approaches for using context in automatic art analysis. In the first one, contextual data is obtained through a multi-task learning model, in which several attributes are trained together to find visual relationships between elements. In the second approach, context is obtained through an art-specific knowledge graph, which encodes relationships between artistic attributes. An exhaustive evaluation of both of our models in several art analysis problems, such as author identification, type classification, or cross-modal retrieval, show that performance is improved by up to 7.3% in art classification and 37.24% in retrieval when context-aware embeddings are used.},
 author = {Garcia, Noa and Renoust, Benjamin and Nakashima, Yuta},
 booktitle = {Proceedings of the 2019 ACM International Conference on Multimedia Retrieval (ICMR)},
 doi = {10.1145/3323873.3325028},
 isbn = {9781450367653},
 keywords = {Art classification,Knowledge graphs,Multi-modal retrieval,buddha,kbqa},
 mendeley-tags = {buddha,kbqa},
 title = {Context-aware embeddings for automatic art analysis},
 year = {2019}
}
