---
# Documentation: https://sourcethemes.com/academic/docs/managing-content/

title: A comparative study of language Transformers for video question answering
subtitle: ''
summary: ''
authors:
- Zekun Yang
- Noa Garcia
- Chenhui Chu
- Mayu Otani
- Yuta Nakashima
- Haruo Takemura
tags: []
categories: []
date: '2021-07-01'
lastmod: 2023-02-15T15:27:33+09:00
featured: false
draft: false

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder.
# Focal points: Smart, Center, TopLeft, Top, TopRight, Left, Right, BottomLeft, Bottom, BottomRight.
image:
  caption: ''
  focal_point: ''
  preview_only: false

# Projects (optional).
#   Associate this post with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `projects = ["internal-project"]` references `content/project/deep-learning/index.md`.
#   Otherwise, set `projects = []`.
projects: []
publishDate: '2023-02-15T06:27:33.640677Z'
publication_types:
- '2'
abstract: With the goal of correctly answering questions about images or videos, visual
  question answering (VQA) has quickly developed in recent years. However, current
  VQA systems mainly focus on answering questions about a single image and face many
  challenges in answering video-based questions. VQA in video not only has to understand
  the evolution between video frames but also requires a certain understanding of
  corresponding subtitles. In this paper, we propose a language Transformer-based
  video question answering model to encode the complex semantics from video clips.
  Different from previous models which represent visual features by recurrent neural
  networks, our model encodes visual concept sequences with a pre-trained language
  Transformer. We investigate the performance of our model using four language Transformers
  over two different datasets. The results demonstrate outstanding improvements compared
  to previous work.
publication: '*Neurocomputing*'
doi: https://doi.org/10.1016/j.neucom.2021.02.092
links:
- name: URL
  url: https://doi.org/10.1016/j.neucom.2021.02.092
---
