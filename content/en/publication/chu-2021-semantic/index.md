---
title: The semantic typology of visually grounded paraphrases
authors:
- Chenhui Chu
- Vinicius Oliveira
- Felix Giovanni Virgo
- Mayu Otani
- Noa Garcia
- Yuta Nakashima
date: '2021-12-01'
publishDate: '2024-01-15T05:00:59.385451Z'
publication_types:
- article-journal
publication: '*Computer Vision and Image Understanding*'
doi: https://doi.org/10.1016/j.cviu.2021.103333
abstract: Visually grounded paraphrases (VGPs) are different phrasal expressions describing
  the same visual concept in an image. Previous studies treat VGP identification as
  a binary classification task, which ignores various phenomena behind VGPs (i.e.,
  different linguistic interpretation of the same visual concept) such as linguistic
  paraphrases and VGPs from different aspects. In this paper, we propose semantic
  typology for VGPs, aiming to elucidate the VGP phenomena and deepen the understanding
  about how human beings interpret vision with language. We construct a large VGP
  dataset that annotates the class to which each VGP pair belongs according to our
  typology. In addition, we present a classification model that fuses language and
  visual features for VGP classification on our dataset. Experiments indicate that
  joint language and vision representation learning is important for VGP classification.
  We further demonstrate that our VGP typology can boost the performance of visually
  grounded textual entailment.
links:
- name: URL
  url: https://www.sciencedirect.com/science/article/pii/S1077314221001697
---
