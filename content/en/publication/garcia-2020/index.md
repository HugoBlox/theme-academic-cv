---
# Documentation: https://sourcethemes.com/academic/docs/managing-content/

title: 'ContextNet: representation and exploration for painting classification and
  retrieval in context'
subtitle: ''
summary: ''
authors:
- Noa Garcia
- Benjamin Renoust
- Yuta Nakashima
tags:
- Art classification
- Knowledge graphs
- Multi-modal retrieval
- Multitask learning
- Visualisation
- Buddha
- Kvqa
categories: []
date: '2020-01-01'
lastmod: 2023-02-15T15:27:44+09:00
featured: false
draft: false

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder.
# Focal points: Smart, Center, TopLeft, Top, TopRight, Left, Right, BottomLeft, Bottom, BottomRight.
image:
  caption: ''
  focal_point: ''
  preview_only: false

# Projects (optional).
#   Associate this post with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `projects = ["internal-project"]` references `content/project/deep-learning/index.md`.
#   Otherwise, set `projects = []`.
projects: []
publishDate: '2023-08-20T08:43:27.873143Z'
publication_types:
- '2'
abstract: 'Â© 2019, The Author(s). In automatic art analysis, models that besides the
  visual elements of an artwork represent the relationships between the different
  artistic attributes could be very informative. Those kinds of relationships, however,
  usually appear in a very subtle way, being extremely difficult to detect with standard
  convolutional neural networks. In this work, we propose to capture contextual artistic
  information from fine-art paintings with a specific ContextNet network. As context
  can be obtained from multiple sources, we explore two modalities of ContextNets:
  one based on multitask learning and another one based on knowledge graphs. Once
  the contextual information is obtained, we use it to enhance visual representations
  computed with a neural network. In this way, we are able to (1) capture information
  about the content and the style with the visual representations and (2) encode relationships
  between different artistic attributes with the ContextNet. We evaluate our models
  on both painting classification and retrieval, and by visualising the resulting
  embeddings on a knowledge graph, we can confirm that our models represent specific
  stylistic aspects present in the data.'
publication: '*International Journal of Multimedia Information Retrieval*'
doi: 10.1007/s13735-019-00189-4
---
