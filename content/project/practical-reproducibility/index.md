---
title: "Reproducible Evaluation of Systems"
summary: "Making delivery of systems research more efficient."
tags:
- reproducibility
date: "2016-04-27T00:00:00Z"

# Optional external URL for project (replaces project detail page).
external_link: ""

image:
  caption: ""
  focal_point: Smart

links: []
url_code: ""
url_pdf: ""
url_slides: ""
url_video: ""

# Slides (optional).
#   Associate this project with Markdown slides.
#   Simply enter your slide deck's filename without extension.
#   E.g. `slides = "example-slides"` references `content/slides/example-slides.md`.
#   Otherwise, set `slides = ""`.
slides: []
---

**Website:** [falsifiable.us](http://falsifiable.us)  
**Funding:** [NSF OAC-1450488](http://bigweatherweb.org/Big_Weather_Web/Home/Home.html), [CROSS](https://cross.ucsc.edu/)  
**Overview:** [USENIX ;login: Winter 2016](https://drive.google.com/file/d/0B5rZ7hI6vXv3bHlxdEpIMkphS0U/view?usp=sharing)  
**Workshops:**

-  [1st International Workshop on Practical Reproducible Evaluation of Computer Systems](https://p-recs.github.io/2018/) (P-RECS 2018) held in conjunction with ACM HPDC 2018.  
- [2nd International Workshop on Practical Reproducible Evaluation of Computer Systems](https://p-recs.github.io/2019/) (P-RECS 2019) held in conjunction with ACM HPDC 2019.
- [3rd International Workshop on Practical Reproducible Evaluation of Computer Systems](https://p-recs.github.io/2020/) (P-RECS 2020) held in conjunction with ACM HPDC 2020.

Independently validating experimental  results in the field of computer systems research is a challenging task. Recreating an environment that resembles the one where an experiment  was originally executed is a time-consuming endeavor. Popper is a  convention (or protocol) for conducting experiments following a DevOps  approach that allows researchers to make all associated artifacts  publicly available with the goal of maximizing automation in the  re-execution of an experiment and validation of its results.
