@article{low-resource-tallip,
 abstract = {Existing supervised solutions for Named Entity Recognition (NER) typically rely on a large annotated corpus. Collecting large amounts of NER annotated corpus is time-consuming and requires considerable human effort. However, collecting small amounts of annotated corpus for any language is feasible, but the performance degrades due to data sparsity. We address the data sparsity by borrowing features from the data of a closely related language. We use hierarchical neural networks to train a supervised NER system. The feature borrowing from a closely related language happens via the shared layers of the network. The neural network is trained on the combined dataset of the low-resource language and a closely related language, also termed Multilingual Learning. Unlike existing systems, we share all layers of the network between the two languages. We apply multilingual learning for NER in Indian languages and empirically show the benefits over a monolingual deep learning system and a traditional machine-learning system with some feature engineering. Using multilingual learning, we show that the low-resource language NER performance increases mainly due to (1) increased named entity vocabulary, (2) cross-lingual subword features, and (3) multilingual learning playing the role of regularization.},
 acmid = {3238797},
 address = {New York, NY, USA},
 articleno = {9},
 author = {Murthy, Rudra and Khapra, Mitesh M. and Bhattacharyya, Pushpak},
 doi = {10.1145/3238797},
 issn = {2375-4699},
 issue_date = {January 2019},
 journal = {ACM Trans. Asian Low-Resour. Lang. Inf. Process.},
 keywords = {indian languages, named entity recognition, deep learning, low-resource languages, multilingual learning},
 month = {dec},
 number = {2},
 numpages = {20},
 pages = {9:1--9:20},
 publisher = {ACM},
 title = {Improving NER Tagging Performance in Low-Resource Languages via Multilingual Learning},
 url = {http://doi.acm.org/10.1145/3238797},
 volume = {18},
 year = {2018}
}

