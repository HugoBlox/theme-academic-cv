---
title: 'Match them up: visually explainable few-shot image classification'
_build:
  render: never
  list: never
  publishResources: false
date: '2022-01-01'
publishDate: '2023-08-20T08:45:13.241185Z'
authors:
- Bowen Wang
- Liangzhi Li
- Manisha Verma
- Yuta Nakashima
- Ryo Kawasaki
- Hajime Nagahara
publication_types:
- '2'
abstract: Few-shot learning (FSL) approaches, mostly neural network-based, assume
  that pre-trained knowledge can be obtained from base (seen) classes and transferred
  to novel (unseen) classes. However, the black-box nature of neural networks makes
  it difficult to understand what is actually transferred, which may hamper FSL application
  in some risk-sensitive areas. In this paper, we reveal a new way to perform FSL
  for image classification, using a visual representation from the backbone model
  and patterns generated by a self-attention based explainable module. The representation
  weighted by patterns only includes a minimum number of distinguishable features
  and the visualized patterns can serve as an informative hint on the transferred
  knowledge. On three mainstream datasets, experimental results prove that the proposed
  method can enable satisfying explainability and achieve high classification results.
  Code is available at https://github.com/wbw520/MTUNet.
featured: false
publication: '*Applied Intelligence*'
doi: https://doi.org/10.1007/s10489-022-04072-4
links:
- name: URL
  url: https://github.com/wbw520/MTUNet
---

