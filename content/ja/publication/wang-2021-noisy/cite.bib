@article{wang2021noisy,
 abstract = {Semantic video segmentation is a key challenge for various applications. This paper presents a new model named Noisy-LSTM, which is trainable in an end-to-end manner, with convolutional LSTMs (ConvLSTMs) to leverage the temporal coherence in video frames, together with a simple yet effective training strategy that replaces a frame in a given video sequence with noises. Our training strategy spoils the temporal coherence in video frames and thus makes the temporal links in ConvLSTMs unreliable; this may consequently improve the ability of the model to extract features from video frames and serve as a regularizer to avoid overfitting, without requiring extra data annotations or computational costs. Experimental results demonstrate that the proposed model can achieve state-of-the-art performances on both the CityScapes and EndoVis2018 datasets. The code for the proposed method is available at https://github.com/wbw520/NoisyLSTM.},
 author = {Bowen Wang and Liangzhi Li and Yuta Nakashima and Ryo Kawasaki and Hajime Nagahara and Yasushi Yagi},
 doi = {https://doi.org/10.1109/ACCESS.2021.3067928},
 journal = {IEEE Access},
 month = {3},
 pages = {pp.~46810--46820},
 title = {Noisy-LSTM: Improving temporal awareness for video semantic segmentation},
 url = {https://doi.org/10.1109/ACCESS.2021.3067928},
 volume = {9},
 year = {2021}
}

