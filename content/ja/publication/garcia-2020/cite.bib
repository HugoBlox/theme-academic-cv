@article{Garcia2020,
 abstract = {Â© 2019, The Author(s). In automatic art analysis, models that besides the visual elements of an artwork represent the relationships between the different artistic attributes could be very informative. Those kinds of relationships, however, usually appear in a very subtle way, being extremely difficult to detect with standard convolutional neural networks. In this work, we propose to capture contextual artistic information from fine-art paintings with a specific ContextNet network. As context can be obtained from multiple sources, we explore two modalities of ContextNets: one based on multitask learning and another one based on knowledge graphs. Once the contextual information is obtained, we use it to enhance visual representations computed with a neural network. In this way, we are able to (1) capture information about the content and the style with the visual representations and (2) encode relationships between different artistic attributes with the ContextNet. We evaluate our models on both painting classification and retrieval, and by visualising the resulting embeddings on a knowledge graph, we can confirm that our models represent specific stylistic aspects present in the data.},
 author = {Garcia, Noa and Renoust, Benjamin and Nakashima, Yuta},
 doi = {10.1007/s13735-019-00189-4},
 journal = {International Journal of Multimedia Information Retrieval},
 keywords = {Art classification,Knowledge graphs,Multi-modal retrieval,Multitask learning,Visualisation,buddha,kvqa},
 mendeley-tags = {buddha,kvqa},
 number = {1},
 title = {ContextNet: representation and exploration for painting classification and retrieval in context},
 volume = {9},
 year = {2020}
}

