@article{Otani2017c,
 abstract = {Authoring video blogs requires a video editing process, which is cumbersome for ordinary users. Video summarization can automate this process by extracting important segments from original videos. Because bloggers typically have certain stories for their blog posts, video summaries of a blog post should take the author's intentions into account. However, most prior works address video summarization by mining patterns from the original videos without considering the blog author's intentions. To generate a video summary that reflects the blog author's intention, we focus on supporting texts in video blog posts and present a text-based method, in which the supporting text serves as a prior to the video summary. Given video and text that describe scenes of interest, our method segments videos and assigns to each video segment its priority in the summary based on its relevance to the input text. Our method then selects a subset of segments with content that is similar to the input text. Accordingly, our method produces different video summaries from the same set of videos, depending on the input text. We evaluated summaries generated from both blog viewers' and authors' perspectives in a user study. Experimental results demonstrate the advantages to the proposed text-based method for video blog authoring.},
 author = {Otani, Mayu and Nakashima, Yuta and Sato, Tomokazu and Yokoya, Naokazu},
 doi = {10.1007/s11042-016-4061-3},
 issn = {15737721},
 journal = {Multimedia Tools and Applications},
 keywords = {Text-based video summarization,User study,Video skimming},
 month = {may},
 number = {9},
 pages = {12097--12115},
 publisher = {Springer New York LLC},
 title = {Video summarization using textual descriptions for authoring video blogs},
 volume = {76},
 year = {2017}
}

