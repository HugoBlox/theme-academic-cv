train %>%
group_by(Type) %>%
summarise(n_stores=n_distinct(Store)) %>%
as_tibble() %>%
glimpse()
#Avg Store Sales by Type
train %>%
group_by(Type,Date) %>%
summarise(totalSales=sum(Weekly_Sales,na.rm = T),
nStores=n_distinct(Store),
avgStoreSale=totalSales/nStores) %>%
ggplot(aes(x=Date,y=avgStoreSale,fill=Type,color=Type))+
geom_line(size=1,alpha=.7)+
xlab("") +
labs(color="Store Type")+
ylab("Avg Weekly Sales")+
scale_y_log10(breaks = trans_breaks("log10", function(x) 10^x),
labels = trans_format("log10", math_format(10^.x)))+
scale_color_manual(values=c("black","dodgerblue","deeppink"))
#nrow=45 * num weeks (unique Dates) (must be grouped for anom.)
storeSums<-train %>%
group_by(Store,Date) %>%
summarise(storeWeeklySales=sum(Weekly_Sales,na.rm = T))
#anomalies
storeAnom<-storeSums %>%
time_decompose(storeWeeklySales) %>%
anomalize(remainder) %>%
time_recompose()
head(storeAnom) %>% mutate_if(is_numeric,round) %>%
tableHTML(rownames = F) %>%
add_css_table(css = list(c('height','width', 'font-size'), c('50','70', '13px'))) %>%
add_css_thead(css= list(c('height','width', 'font-size'), c('30','70', '13px')))
storesList<-stores %>% pull(Store)
storeAnom %>%
filter(anomaly=="Yes") %>%
group_by(Date) %>%
tally %>%
tail()
storeAnom %>%
filter(Store %in% tail(storesList,3)) %>%
plot_anomalies(ncol = 4, alpha_dots = 0.25,time_recomposed = T)
storeAnom %>%
filter(Store %in% head(storesList,12)) %>%
plot_anomalies(ncol = 4, alpha_dots = 0.25,time_recomposed = T)
isAnom<-storeAnom %>% ungroup() %>% select(Store,Date,anomaly) %>%  setDT()
train<-setDT(train)[isAnom,on=c("Store","Date")]
test<-setDT(test)[isAnom,on=c("Store","Date")]
#train recipe
train %>%
summarize_all(~sum(is.na(.)))
train
View(test)
#vector of filenames
fileslist<-c("features.csv","stores.csv","test.csv","train.csv")
dfNames<-map_chr(fileslist,~str_extract(.x,"[^.]+"))
dfNames
dfs<-map(fileslist,read_csv)
for(i in seq_along(dfNames)){
assign(dfNames[i],dfs[[i]])
}
#joining on store & date (keep number rows in train test)
train<-setDT(train)[setDT(features),on=c("Store","Date","IsHoliday"),nomatch=0]
test<-setDT(test)[setDT(features),on=c("Store","Date","IsHoliday"),nomatch=0]
#join stores & train/test on store number
train<-train[setDT(stores),on="Store",nomatch=0]
test<-test[setDT(stores),on="Store",nomatch=0]
curNames<-train %>% select(MarkDown1:MarkDown5) %>% names()
newNames<- paste("MDwn",str_extract(curNames,"[0-9]+"),sep ="")
train<-train %>% setnames(curNames,newNames)
train %>% set_names(str_trunc(names(train),width = 5,ellipsis = "")) %>%
head() %>%
mutate_if(is.numeric,round) %>%
tableHTML() %>%
add_css_table(css = list(c('height','width', 'font-size'), c('50','70', '11px')))
train %>%
select(Store,Dept) %>%
summarise_all(~n_distinct(.x))
#add number of departments in store as feature to training dataset
train<-train %>%
group_by(Store) %>%
mutate(num_dept=n_distinct(Dept))
View(test)
test<-test %>% setnames(curNames,newNames)
train %>% set_names(str_trunc(names(train),width = 5,ellipsis = "")) %>%
head() %>%
mutate_if(is.numeric,round) %>%
tableHTML() %>%
add_css_table(css = list(c('height','width', 'font-size'), c('50','70', '11px')))
train %>% set_names(str_trunc(names(train),width = 5,ellipsis = "")) %>%
head() %>%
mutate_if(is.numeric,round) %>%
tableHTML() %>%
add_css_table(css = list(c('height','width', 'font-size'), c('50','70', '11px')))
train %>%
select(Store,Dept) %>%
summarise_all(~n_distinct(.x))
#add number of departments in store as feature to training dataset
train<-train %>%
group_by(Store) %>%
mutate(num_dept=n_distinct(Dept))
test<-test %>%
group_by(Store) %>%
mutate(num_dept=n_distinct(Dept))
first_stores<-head(unique(train$Store),3)
first_dept<-head(unique(train$Dept),3)
gg<-train %>% filter(Store %in% first_stores & Dept %in% first_dept) %>%
ggplot(aes(x = Date, y = Weekly_Sales)) +
geom_line() +
theme(legend.position="bottom") +
facet_grid(Store~Dept,scales="free_y",space = "free",labeller = label_both)+
xlab("") +
ylab("")+
geom_smooth()
ggplotly(gg,height = 350, width=600)
#-hist?
train %>% select_if(is.numeric) %>%
select(-Store,-Dept) %>%
gather("var","value") %>%
ggplot(aes(x=value))+
geom_histogram()+
facet_wrap(~var,scales = "free")
#Number of stores in each type (22,17,6)
train %>%
group_by(Type) %>%
summarise(n_stores=n_distinct(Store)) %>%
as_tibble() %>%
glimpse()
#Avg Store Sales by Type
train %>%
group_by(Type,Date) %>%
summarise(totalSales=sum(Weekly_Sales,na.rm = T),
nStores=n_distinct(Store),
avgStoreSale=totalSales/nStores) %>%
ggplot(aes(x=Date,y=avgStoreSale,fill=Type,color=Type))+
geom_line(size=1,alpha=.7)+
xlab("") +
labs(color="Store Type")+
ylab("Avg Weekly Sales")+
scale_y_log10(breaks = trans_breaks("log10", function(x) 10^x),
labels = trans_format("log10", math_format(10^.x)))+
scale_color_manual(values=c("black","dodgerblue","deeppink"))
#nrow=45 * num weeks (unique Dates) (must be grouped for anom.)
storeSums<-train %>%
group_by(Store,Date) %>%
summarise(storeWeeklySales=sum(Weekly_Sales,na.rm = T))
#anomalies
storeAnom<-storeSums %>%
time_decompose(storeWeeklySales) %>%
anomalize(remainder) %>%
time_recompose()
head(storeAnom) %>% mutate_if(is_numeric,round) %>%
tableHTML(rownames = F) %>%
add_css_table(css = list(c('height','width', 'font-size'), c('50','70', '13px'))) %>%
add_css_thead(css= list(c('height','width', 'font-size'), c('30','70', '13px')))
storeSums
isAnom<-storeAnom %>% ungroup() %>% select(Store,Date,anomaly) %>%  setDT()
train<-setDT(train)[isAnom,on=c("Store","Date")]
test<-setDT(test)[isAnom,on=c("Store","Date")]
test
train
#vector of filenames
fileslist<-c("features.csv","stores.csv","test.csv","train.csv")
dfNames<-map_chr(fileslist,~str_extract(.x,"[^.]+"))
dfNames
dfs<-map(fileslist,read_csv)
for(i in seq_along(dfNames)){
assign(dfNames[i],dfs[[i]])
}
test<-setDT(test)[setDT(features),on=c("Store","Date","IsHoliday"),nomatch=0]
test<-test[setDT(stores),on="Store",nomatch=0]
test<-test %>% setnames(curNames,newNames)
test<-test %>%
group_by(Store) %>%
mutate(num_dept=n_distinct(Dept))
train
train
#train recipe
train %>%
summarize_all(~sum(is.na(.)))
library(blogdown)
serve_site()
train
library(recipes)
library(tidyverse)
library(knitr)
library(plotly)
library(anomalize)
library(data.table)
library(scales)
library(lubridate)
library(tableHTML)
#vector of filenames
fileslist<-c("features.csv","stores.csv","test.csv","train.csv")
dfNames<-map_chr(fileslist,~str_extract(.x,"[^.]+"))
dfNames
dfs<-map(fileslist,read_csv)
for(i in seq_along(dfNames)){
assign(dfNames[i],dfs[[i]])
}
#joining on store & date (keep number rows in train test)
train<-setDT(train)[setDT(features),on=c("Store","Date","IsHoliday"),nomatch=0]
test<-setDT(test)[setDT(features),on=c("Store","Date","IsHoliday"),nomatch=0]
#join stores & train/test on store number
train<-train[setDT(stores),on="Store",nomatch=0]
test<-test[setDT(stores),on="Store",nomatch=0]
curNames<-train %>% select(MarkDown1:MarkDown5) %>% names()
newNames<- paste("MDwn",str_extract(curNames,"[0-9]+"),sep ="")
train<-train %>% setnames(curNames,newNames)
test<-test %>% setnames(curNames,newNames)
train %>% set_names(str_trunc(names(train),width = 5,ellipsis = "")) %>%
head() %>%
mutate_if(is.numeric,round) %>%
tableHTML() %>%
add_css_table(css = list(c('height','width', 'font-size'), c('50','70', '11px')))
train %>%
select(Store,Dept) %>%
summarise_all(~n_distinct(.x))
#add number of departments in store as feature to training dataset
train<-train %>%
group_by(Store) %>%
mutate(num_dept=n_distinct(Dept))
test<-test %>%
group_by(Store) %>%
mutate(num_dept=n_distinct(Dept))
first_stores<-head(unique(train$Store),3)
first_dept<-head(unique(train$Dept),3)
gg<-train %>% filter(Store %in% first_stores & Dept %in% first_dept) %>%
ggplot(aes(x = Date, y = Weekly_Sales)) +
geom_line() +
theme(legend.position="bottom") +
facet_grid(Store~Dept,scales="free_y",space = "free",labeller = label_both)+
xlab("") +
ylab("")+
geom_smooth()
ggplotly(gg,height = 350, width=600)
#-hist?
train %>% select_if(is.numeric) %>%
select(-Store,-Dept) %>%
gather("var","value") %>%
ggplot(aes(x=value))+
geom_histogram()+
facet_wrap(~var,scales = "free")
#Number of stores in each type (22,17,6)
train %>%
group_by(Type) %>%
summarise(n_stores=n_distinct(Store)) %>%
as_tibble() %>%
glimpse()
#Avg Store Sales by Type
train %>%
group_by(Type,Date) %>%
summarise(totalSales=sum(Weekly_Sales,na.rm = T),
nStores=n_distinct(Store),
avgStoreSale=totalSales/nStores) %>%
ggplot(aes(x=Date,y=avgStoreSale,fill=Type,color=Type))+
geom_line(size=1,alpha=.7)+
xlab("") +
labs(color="Store Type")+
ylab("Avg Weekly Sales")+
scale_y_log10(breaks = trans_breaks("log10", function(x) 10^x),
labels = trans_format("log10", math_format(10^.x)))+
scale_color_manual(values=c("black","dodgerblue","deeppink"))
#nrow=45 * num weeks (unique Dates) (must be grouped for anom.)
storeSums<-train %>%
group_by(Store,Date) %>%
summarise(storeWeeklySales=sum(Weekly_Sales,na.rm = T))
#anomalies
storeAnom<-storeSums %>%
time_decompose(storeWeeklySales) %>%
anomalize(remainder) %>%
time_recompose()
head(storeAnom) %>% mutate_if(is_numeric,round) %>%
tableHTML(rownames = F) %>%
add_css_table(css = list(c('height','width', 'font-size'), c('50','70', '13px'))) %>%
add_css_thead(css= list(c('height','width', 'font-size'), c('30','70', '13px')))
storesList<-stores %>% pull(Store)
storeAnom %>%
filter(anomaly=="Yes") %>%
group_by(Date) %>%
tally %>%
tail()
storeAnom %>%
filter(Store %in% tail(storesList,3)) %>%
plot_anomalies(ncol = 4, alpha_dots = 0.25,time_recomposed = T)
storeAnom %>%
filter(Store %in% head(storesList,12)) %>%
plot_anomalies(ncol = 4, alpha_dots = 0.25,time_recomposed = T)
isAnom<-storeAnom %>% ungroup() %>% select(Store,Date,anomaly) %>%  setDT()
train<-setDT(train)[isAnom,on=c("Store","Date")]
#train recipe
train %>%
summarize_all(~sum(is.na(.)))
train
train %>%
group_by(Store, Date) %>%
summarize(
sumWeeklySales=sum(Weekly_Sales),
#number department anom
dpt_anoms=sum(isAnom=="Yes")
) %>%
slice(1)
train %>%
group_by(Store, Date) %>%
summarize(
sumWeeklySales=sum(Weekly_Sales),
#number department anom
dpt_anoms=sum(isAnom=="Yes")
)
train
train %>%
group_by(Store, Date) %>%
summarize(
sumWeeklySales=sum(Weekly_Sales),
#number department anom
dpt_anoms=sum(anomaly=="Yes")
) %>%
slice(1)
train %>%
group_by(Store, Date) %>%
summarize(
sumWeeklySales=sum(Weekly_Sales),
#number department anom
dpt_anoms=sum(anomaly=="Yes")
)
train %>%
group_by(Store, Date) %>%
mutate(
sumWeeklySales=sum(Weekly_Sales),
#number department anom
dpt_anoms=sum(anomaly=="Yes")
)
train %>%
group_by(Store, Date) %>%
mutate(
sumWeeklySales=sum(Weekly_Sales),
#number department anom
dpt_anoms=sum(anomaly=="Yes")
) %>%
slice(1)
?top_n
?UNIQUE
?unique
train %>%
group_by(Store, Date) %>%
mutate(
sumWeeklySales=sum(Weekly_Sales),
#number department anom
dpt_anoms=sum(anomaly=="Yes")
) %>%
ungroup() %>%
select(-Dept) %>%
data.table::unique(by=c("Store","Dept"))
train %>%
group_by(Store, Date) %>%
mutate(
sumWeeklySales=sum(Weekly_Sales),
#number department anom
dpt_anoms=sum(anomaly=="Yes")
) %>%
ungroup() %>%
select(-Dept) %>%
unique(by=c("Store","Dept"))
train %>%
group_by(Store, Date) %>%
mutate(
sumWeeklySales=sum(Weekly_Sales),
#number department anom
dpt_anoms=sum(anomaly=="Yes")
) %>%
ungroup() %>%
select(-Dept) %>%
unique(by=c("Store","Date"))
is.data.table(train)
train %>%
group_by(Store, Date) %>%
mutate(
sumWeeklySales=sum(Weekly_Sales),
#number department anom
dpt_anoms=sum(anomaly=="Yes")
) %>%
ungroup() %>%
select(-Dept,-Weekly_Sales,-anomaly) %>%
unique(by=c("Store","Date"))
autocor_func <- function(data, value, lags = 0:20) {
value_expr <- enquo(value)
acf_values <- data %>%
select(!! value_expr) %>%
pull() %>%
acf(lag.max = tail(lags, 1), plot = FALSE) %>%
.$acf %>%
.[,,1]
ret <- tibble(acf = acf_values) %>%
rowid_to_column(var = "lag") %>%
mutate(lag = lag - 1) %>%
filter(lag %in% lags)
return(ret)
}
g <- train %>%
autocor_func(sumWeeklySales, lags = 0:nrow(.)) %>%
ggplot(aes(lag, acf)) +
geom_point(alpha = 0.5, color = "#2c3e50") +
expand_limits(y = c(-1, 1)) +
theme_minimal() +
labs(title = "Autocorrelation")
head(train)
train<-train %>%
group_by(Store, Date) %>%
mutate(
sumWeeklySales=sum(Weekly_Sales),
#number department anom
dpt_anoms=sum(anomaly=="Yes")
) %>%
ungroup() %>%
select(-Dept,-Weekly_Sales,-anomaly) %>%
unique(by=c("Store","Date"))
head(train)
autocor_func <- function(data, value, lags = 0:20) {
value_expr <- enquo(value)
acf_values <- data %>%
select(!! value_expr) %>%
pull() %>%
acf(lag.max = tail(lags, 1), plot = FALSE) %>%
.$acf %>%
.[,,1]
ret <- tibble(acf = acf_values) %>%
rowid_to_column(var = "lag") %>%
mutate(lag = lag - 1) %>%
filter(lag %in% lags)
return(ret)
}
g <- train %>%
autocor_func(sumWeeklySales, lags = 0:nrow(.)) %>%
ggplot(aes(lag, acf)) +
geom_point(alpha = 0.5, color = "#2c3e50") +
expand_limits(y = c(-1, 1)) +
theme_minimal() +
labs(title = "Autocorrelation")
ggplotly(g)
autocor_func <- function(data, value, lags = 0:20) {
value_expr <- enquo(value)
acf_values <- data %>%
select(!! value_expr) %>%
pull() %>%
acf(lag.max = tail(lags, 1), plot = FALSE) %>%
.$acf %>%
.[,,1]
ret <- tibble(acf = acf_values) %>%
rowid_to_column(var = "lag") %>%
mutate(lag = lag - 1) %>%
filter(lag %in% lags)
return(ret)
}
g <- train %>%
autocor_func(sumWeeklySales, lags = 0:nrow(.)) %>%
ggplot(aes(lag, acf)) +
geom_point(alpha = 0.5, color = "blue") +
expand_limits(y = c(-1, 1)) +
theme_minimal() +
labs(title = "Autocorrelation")
ggplotly(g)
g <- train %>%
autocor_func(sumWeeklySales, lags = 0:nrow(.)) %>%
ggplot(aes(lag, acf)) +
geom_point(alpha = 0.5, color = "dodgerblue") +
expand_limits(y = c(-1, 1)) +
theme_minimal() +
labs(title = "Autocorrelation")
ggplotly(g)
g <- train %>%
autocor_func(sumWeeklySales, lags = 0:nrow(.)) %>%
ggplot(aes(lag, acf)) +
geom_point(alpha = 0.5, color = "maroon") +
expand_limits(y = c(-1, 1)) +
labs(title = "Weekly Sales Autocorrelation")
ggplotly(g,height = 350,width = 600)
df<-train
col_name<-train %>% select(sumWeeklySales)
col_name_nse <- enquo(col_name)
df %>%
select(!! col_name_nse) %>%
pull() %>%
acf(lag.max = tail(lags, 1), plot = FALSE) %>%
.$acf %>%
.[,,1]
df %>%
select(!! col_name_nse) %>%
pull()
autocor_func <- function(data, col_name, lags = 0:30) {
col_name_nse <- enquo(col_name)
acf_values <- data %>%
select(!! col_name_nse) %>%
pull() %>%
acf(lag.max = tail(lags, 1), plot = FALSE) %>%
.$acf %>%
.[,,1]
ret <- tibble(acf = acf_values) %>%
rowid_to_column(var = "lag") %>%
mutate(lag = lag - 1) %>%
filter(lag %in% lags)
return(ret)
}
g <- train %>%
autocor_func(sumWeeklySales, lags = 0:nrow(.)) %>%
ggplot(aes(lag, acf)) +
geom_point(alpha = 0.5, color = "maroon") +
expand_limits(y = c(-1, 1)) +
labs(title = "Weekly Sales Autocorrelation")
ggplotly(g,height = 350,width = 600)
train %>%
autocor_func(sumWeeklySales, lags = 0:nrow(.))
library(blogdown)
serve_site()
