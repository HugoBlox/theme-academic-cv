kable(head(rdf_bin)) %>%
kable_styling(bootstrap_options = "striped", full_width = F,font_size = 8) %>%
scroll_box(width = "500px", height = "200px")
# get text of review
text<-rdf_bin$review
max_features <- 1000
tokenizer <- text_tokenizer(num_words = max_features)
#fit tokenizer to actual reviews
tokenizer %>%
fit_text_tokenizer(text)
#num reviews (after removing rating=3)
print(tokenizer$document_count)
#create list of integers for reviews
text_seqs <- texts_to_sequences(tokenizer, text)
head(tokenizer)
tokenizer
tokenizer.head()
#cut reviews off after 100 words
max_len <- 100
#define train data
x_train <- pad_sequences(text_seqs,maxlen = maxlen)
dim(x_train)
y_train <- rdf_bin$positive
length(y_train)
install.packages('rsample')
?initialsplit()
?initial_split()
?rsample
library(rsample)
install.packages('tidymodels')
install.packages('tidymodels')
install.packages("tidymodels")
library("blogdown", lib.loc="/Library/Frameworks/R.framework/Versions/3.4/Resources/library")
library(tidyverse)
library(zoo)
library(knitr)
library(tidytext)
library(SnowballC)
library(keras)
library(kableExtra)
library(rsample)
#load data
rdf<-readRDS("first_3000.Rda")
str(rdf)
#rename & change variable type
rdf <- rdf %>% rename(stay_date = id_date,
review = reviews) %>%
mutate_at(vars(stay_date, review),
~ as.character(.)) %>%
mutate(rating = as.factor(rating))
#change stay_date variable from character to date type
rdf$stay_date <- gsub("Date of stay: ", "", rdf$stay_date)
rdf$stay_date <- as.yearmon(rdf$stay_date, "%b %Y")
head(rdf)
rdf_bin<-rdf %>% mutate(review_num = row_number()) %>% filter(!rating==3) %>%
mutate(positive = case_when(rating == "1"|rating =="2" ~ 0,TRUE~1)) %>% select(-rating,-stay_date)
split=initial_split(rdf_bin,proportion=.8)
train_data=training(split)
test_data=testing(split)
train_text<-train_data$review
test_text<-test_data$review
max_features <- 1000
train_tokenizer <- text_tokenizer(num_words = max_features)
test_tokenizer <- text_tokenizer(num_words = max_features)
#fit tokenizer to actual reviews
train_tokenizer %>%
fit_text_tokenizer(train_text)
test_tokenizer %>%
fit_text_tokenizer(test_text)
#num train reviews (after removing rating=3)
print(train_tokenizer$document_count)
#list of integers for reviews
train_text_seqs<- texts_to_sequences(train_tokenizer, train_text)
test_text_seqs<- texts_to_sequences(test_tokenizer, test_text)
#cut reviews off after 100 words
max_len <- 100
#define train data
x_train <- pad_sequences(train_text_seqs,maxlen = maxlen)
x_test <- pad_sequences(test_text_seqs,maxlen = maxlen)
dim(x_train)
y_train <- train_data$positive
y_test<-test_data$positive
length(y_train)
batch_size <- 32
embedding_dims <- 50
filters <- 64
kernel_size <- 3
hidden_dims <- 50
epochs <- 10
#### Build Network: Layers, Hidden Units, Activation Function
#vocab size same as max_feat (total vocabulary count used for reviews)
vocab_size<-1000
model <- keras_model_sequential() %>%
#embedding layer
layer_embedding(input_dim = vocab_size, embedding_dims, input_length = maxlen) %>%
layer_dropout(0.2) %>%
layer_conv_1d(
filters, kernel_size,
padding = "valid", activation = "relu", strides = 1
) %>%
layer_global_max_pooling_1d() %>%
layer_dense(units=hidden_dims, activation = "relu") %>%
layer_dropout(0.2) %>%
layer_dense(units=1,activation = "sigmoid")
model %>% summary()
#### Choosing Loss Function & Optimizer
model %>% compile(
loss = "binary_crossentropy",
optimizer = "adam",
metrics = "accuracy"
)
hist <- model %>%
fit(
x_train,
y_train,
batch_size = 32,
epochs = 10,
validation_split = 0.2
)
model %>% predict(x_test[1:10,])
x_test
x_test <- pad_sequences(test_text_seqs,maxlen = maxlen)
dim(x_train)
y_train <- train_data$positive
y_test<-test_data$positive
length(y_train)
library(tidyverse)
library(tidyverse)
library(zoo)
library(knitr)
library(tidytext)
library(SnowballC)
library(keras)
library(kableExtra)
library(rsample)
#load data
rdf<-readRDS("first_3000.Rda")
str(rdf)
#rename & change variable type
rdf <- rdf %>% rename(stay_date = id_date,
review = reviews) %>%
mutate_at(vars(stay_date, review),
~ as.character(.)) %>%
mutate(rating = as.factor(rating))
#change stay_date variable from character to date type
rdf$stay_date <- gsub("Date of stay: ", "", rdf$stay_date)
rdf$stay_date <- as.yearmon(rdf$stay_date, "%b %Y")
head(rdf)
rdf_bin<-rdf %>% mutate(review_num = row_number()) %>% filter(!rating==3) %>%
mutate(positive = case_when(rating == "1"|rating =="2" ~ 0,TRUE~1)) %>% select(-rating,-stay_date)
split=initial_split(rdf_bin,proportion=.8)
train_data=training(split)
test_data=testing(split)
train_text<-train_data$review
test_text<-test_data$review
max_features <- 1000
train_tokenizer <- text_tokenizer(num_words = max_features)
test_tokenizer <- text_tokenizer(num_words = max_features)
#fit tokenizer to actual reviews
train_tokenizer %>%
fit_text_tokenizer(train_text)
test_tokenizer %>%
fit_text_tokenizer(test_text)
#num train reviews (after removing rating=3)
print(train_tokenizer$document_count)
#list of integers for reviews
train_text_seqs<- texts_to_sequences(train_tokenizer, train_text)
test_text_seqs<- texts_to_sequences(test_tokenizer, test_text)
#cut reviews off after 100 words
max_len <- 100
#define train data
x_train <- pad_sequences(train_text_seqs,maxlen = maxlen)
x_test <- pad_sequences(test_text_seqs,maxlen = maxlen)
dim(x_train)
y_train <- train_data$positive
y_test<-test_data$positive
length(y_train)
# Network parameters
batch_size <- 32
embedding_dims <- 50
filters <- 64
kernel_size <- 3
hidden_dims <- 50
epochs <- 10
#### Build Network: Layers, Hidden Units, Activation Function
#vocab size same as max_feat (total vocabulary count used for reviews)
vocab_size<-1000
model <- keras_model_sequential() %>%
#embedding layer
layer_embedding(input_dim = vocab_size, embedding_dims, input_length = maxlen) %>%
layer_dropout(0.2) %>%
layer_conv_1d(
filters, kernel_size,
padding = "valid", activation = "relu", strides = 1
) %>%
layer_global_max_pooling_1d() %>%
layer_dense(units=hidden_dims, activation = "relu") %>%
layer_dropout(0.2) %>%
layer_dense(units=1,activation = "sigmoid")
model %>% summary()
#### Choosing Loss Function & Optimizer
model %>% compile(
loss = "binary_crossentropy",
optimizer = "adam",
metrics = "accuracy"
)
hist <- model %>%
fit(
x_train,
y_train,
batch_size = 32,
epochs = 10,
validation_split = 0.2
)
model %>% predict(x_test[1:10,])
library(tidyverse)
library(zoo)
library(knitr)
library(tidytext)
library(SnowballC)
library(keras)
library(kableExtra)
#load data
rdf<-readRDS("first_3000.Rda")
str(rdf)
#rename & change variable type
rdf <- rdf %>% rename(stay_date = id_date,
review = reviews) %>%
mutate_at(vars(stay_date, review),
~ as.character(.)) %>%
mutate(rating = as.factor(rating))
#change stay_date variable from character to date type
rdf$stay_date <- gsub("Date of stay: ", "", rdf$stay_date)
rdf$stay_date <- as.yearmon(rdf$stay_date, "%b %Y")
head(rdf)
#rename & change variable type
rdf <- rdf %>% rename(stay_date = id_date,
review = reviews) %>%
mutate_at(vars(stay_date, review),
~ as.character(.)) %>%
mutate(rating = as.factor(rating))
library(tidyverse)
library(zoo)
library(knitr)
library(tidytext)
library(SnowballC)
library(keras)
library(kableExtra)
#load data
rdf<-readRDS("first_3000.Rda")
str(rdf)
#rename & change variable type
rdf <- rdf %>% rename(stay_date = id_date,
review = reviews) %>%
mutate_at(vars(stay_date, review),
~ as.character(.)) %>%
mutate(rating = as.factor(rating))
#change stay_date variable from character to date type
rdf$stay_date <- gsub("Date of stay: ", "", rdf$stay_date)
rdf$stay_date <- as.yearmon(rdf$stay_date, "%b %Y")
kable(head(rdf)) %>% kable_styling(bootstrap_options = "striped", full_width = F,font_size = 8) %>%
scroll_box(width = "500px", height = "200px")
#rename & change variable type
rdf <- rdf %>% rename(stay_date = id_date,
review = reviews) %>%
mutate_at(vars(stay_date, review),
~ as.character(.)) %>%
mutate(rating = as.factor(rating))
#load data
rdf<-readRDS("first_3000.Rda")
str(rdf)
#rename & change variable type
rdf <- rdf %>% rename(stay_date = id_date,
review = reviews) %>%
mutate_at(vars(stay_date, review),
~ as.character(.)) %>%
mutate(rating = as.factor(rating))
#change stay_date variable from character to date type
rdf$stay_date <- gsub("Date of stay: ", "", rdf$stay_date)
rdf$stay_date <- as.yearmon(rdf$stay_date, "%b %Y")
kable(head(rdf)) %>% kable_styling(bootstrap_options = "striped", full_width = F,font_size = 8)
#rename & change variable type
rdf <- rdf %>% rename(stay_date = id_date,
review = reviews) %>%
mutate_at(vars(stay_date, review),
~ as.character(.)) %>%
mutate(rating = as.factor(rating))
#load data
rdf<-readRDS("first_3000.Rda")
str(rdf)
#rename & change variable type
rdf <- rdf %>% rename(stay_date = id_date,
review = reviews) %>%
mutate_at(vars(stay_date, review),
~ as.character(.)) %>%
mutate(rating = as.factor(rating))
#change stay_date variable from character to date type
rdf$stay_date <- gsub("Date of stay: ", "", rdf$stay_date)
rdf$stay_date <- as.yearmon(rdf$stay_date, "%b %Y")
kable(head(rdf),1) %>% kable_styling(bootstrap_options = "striped", full_width = F,font_size = 8)
#load data
rdf<-readRDS("first_3000.Rda")
str(rdf)
#rename & change variable type
rdf <- rdf %>% rename(stay_date = id_date,
review = reviews) %>%
mutate_at(vars(stay_date, review),
~ as.character(.)) %>%
mutate(rating = as.factor(rating))
#change stay_date variable from character to date type
rdf$stay_date <- gsub("Date of stay: ", "", rdf$stay_date)
rdf$stay_date <- as.yearmon(rdf$stay_date, "%b %Y")
kable(head(rdf,1)) %>% kable_styling(bootstrap_options = "striped", full_width = F,font_size = 8)
kable(head(rdf,2)) %>% kable_styling(bootstrap_options = "striped", full_width = F,font_size = 8)
kable(head(rdf,3)) %>% kable_styling(bootstrap_options = "striped", full_width = F,font_size = 8)
kable(head(rdf,3)) %>% kable_styling(bootstrap_options = "striped", full_width = F,font_size = 8) %>%
scroll_box(width = "500px", height = "200px")
kable(head(rdf,3)) %>% kable_styling(bootstrap_options = "striped", full_width = F,font_size = 8)
rdf_tidy <- rdf %>% mutate(review_num = row_number()) %>%
unnest_tokens(word, review) %>%
anti_join(stop_words) %>% filter(str_detect(word, "^[a-z']+$")) %>%
distinct()
most_common_words <- rdf_tidy %>%
group_by(word) %>%
summarize(freq = n()) %>%
arrange(desc(freq))
#rearrange by frequency, eliminate duplicates
most_common_words %>%
mutate(word = reorder(word, freq)) %>%
head(25) %>%  ggplot(aes(x = word, y = freq)) + geom_segment(aes(
x = word ,
xend = word,
y = 0,
yend = freq
), color = "black") +
geom_point(size = 3, color = "deepskyblue") +
labs(title = "Top 25 Most Common Words in Review Text", y = "# times used", x =
"") + coord_flip()
#group rating 1&2 into "low" category; rating 3,4,& 5 & into "high" category
by_rate <- rdf %>%
mutate(rating_group = case_when(rating == "1" |
rating == "2" ~ "low", TRUE ~ "high"))
by_rate_inverse <- by_rate %>% unnest_tokens(word, review) %>%
count(rating_group, word, sort = TRUE) %>% filter(!nchar(word) <= 3) %>%
bind_tf_idf(word, rating_group, n) %>% group_by(rating_group) %>%
mutate(rank = rank(desc(tf_idf), ties.method = "first")) %>%
arrange(rank)
by_rate_inverse %>%
mutate(word = factor(word, levels = rev(unique(word)))) %>%
group_by(rating_group) %>% filter(rank <= 10) %>%
ungroup() %>%
ggplot(aes(word, tf_idf, fill = rating_group)) +
geom_col(show.legend = FALSE) +
labs(x = NULL, y = "tf-idf") +
facet_wrap( ~ rating_group, ncol = 2, scales = "free") +
coord_flip()
##bigram: separate-->filter out stop words; put back together-->count
bigram_filt<-rdf %>%
unnest_tokens(bigram, review, token = "ngrams", n = 2) %>%
separate(bigram, c("word1", "word2"), sep = " ") %>%
filter(!word1 %in% stop_words$word) %>%
filter(!word2 %in% stop_words$word)
bigram_count <- bigram_filt %>%
unite(bigram, word1, word2, sep = " ") %>%
count(bigram, sort = TRUE)
bigram_count %>% filter(!str_detect(bigram,"floridian")) %>% head(25) %>%  mutate(bigram = reorder(bigram, n)) %>%
ggplot(aes(x=bigram,y=n))+ geom_segment(aes(x=bigram ,xend=bigram, y=0, yend=n),color="black") +
geom_point(size=3, color="deepskyblue")+
labs(title = "Top 25 Most Common Bigrams in Review Text", y = "# times used", x="") + coord_flip()
sentiment_lexicons <- sentiments %>%
filter(lexicon != "loughran")%>%
group_by(lexicon) %>%
mutate(words_in_lexicon = n_distinct(word)) %>%
ungroup()
sentiment_lexicons %>%
group_by(lexicon) %>%
summarise(distinct_words = n_distinct(word)) %>%
ungroup()
rdf_tidy %>%
mutate(words_in_reviews = n_distinct(word)) %>%
inner_join(sentiment_lexicons) %>%
group_by(lexicon, words_in_reviews, words_in_lexicon) %>%
summarise(num_match = n_distinct(word)) %>%
ungroup() %>%
mutate(match_ratio = num_match / words_in_reviews) %>%
select(lexicon, words_in_reviews, num_match, match_ratio)
#get negative words
bingnegative <- get_sentiments("bing") %>%
filter(sentiment == "negative")
#normalize w/count of total words in reviews for given stay date
wordcounts <- rdf_tidy %>%
group_by(stay_date) %>%
summarize(words = n())
most_neg<-rdf_tidy %>%
semi_join(bingnegative) %>%
group_by(stay_date) %>%
summarize(negativewords = n()) %>%
left_join(wordcounts, by = c("stay_date")) %>%
mutate(ratio_neg = negativewords/words,ratio_pos=1-ratio_neg) %>%
ungroup()
most_neg %>% ggplot(aes(x=stay_date,y=ratio_neg,color=ratio_neg))+scale_x_yearmon(format = "%b-%y")+geom_line()
#get negative words
bingnegative <- get_sentiments("bing") %>%
filter(sentiment == "negative")
#normalize w/count of total words in reviews for given stay date
wordcounts <- rdf_tidy %>%
group_by(stay_date) %>%
summarize(words = n())
most_neg<-rdf_tidy %>%
semi_join(bingnegative) %>%
group_by(stay_date) %>%
summarize(negativewords = n()) %>%
left_join(wordcounts, by = c("stay_date")) %>%
mutate(ratio_neg = negativewords/words,ratio_pos=1-ratio_neg) %>%
ungroup()
most_neg %>% ggplot(aes(x=stay_date,y=ratio_neg,color=ratio_neg))+scale_x_yearmon(format = "%b-%y")+geom_line()
mean(most_neg$ratio_neg)
#get negative words
bingnegative <- get_sentiments("bing") %>%
filter(sentiment == "negative")
#normalize w/count of total words in reviews for given stay date
wordcounts <- rdf_tidy %>%
group_by(stay_date) %>%
summarize(words = n())
most_neg<-rdf_tidy %>%
semi_join(bingnegative) %>%
group_by(stay_date) %>%
summarize(negativewords = n()) %>%
left_join(wordcounts, by = c("stay_date")) %>%
mutate(ratio_neg = negativewords/words,ratio_pos=1-ratio_neg) %>%
ungroup()
most_neg %>% ggplot(aes(x=stay_date,y=ratio_neg,color=ratio_neg))+scale_x_yearmon(format = "%b-%y")+geom_line()
mean(most_neg$ratio_neg)
##gives word and score
afinn <- sentiments %>%
filter(lexicon == "AFINN") %>%
select(word, afinn_score = score)
reviews_sentiment <- rdf_tidy %>%
inner_join(afinn, by = "word") %>%
group_by(review_num, rating) %>%
summarize(sentiment = mean(afinn_score))
reviews_sentiment
ggplot(reviews_sentiment, aes(rating, sentiment, group = rating)) +
geom_boxplot(colour = "black",
fill = "#56B4E9",
notch = T) +
ylab("Average sentiment score")
##gives word and score
afinn <- sentiments %>%
filter(lexicon == "AFINN") %>%
select(word, afinn_score = score)
reviews_sentiment <- rdf_tidy %>%
inner_join(afinn, by = "word") %>%
group_by(review_num, rating) %>%
summarize(sentiment = mean(afinn_score))
ggplot(reviews_sentiment, aes(rating, sentiment, group = rating)) +
geom_boxplot(colour = "black",
fill = "#56B4E9",
notch = T) +
ylab("Average sentiment score")
##Which words tend to appear in positive/negative reviews?-->per-word summary
##returns how many times word used in each review
count_words <- rdf_tidy %>%
count(review_num, rating, word) %>%
ungroup()
#returns most negative words
summary_neg<- count_words %>%  group_by(word) %>%
summarize(reviews = n(),
uses = sum(n),
average_rat = mean(as.integer(rating))) %>% filter(reviews>10) %>% arrange(average_rat)
head(summary_neg,15) %>% ggplot(aes(x=reviews,y=average_rat))+ geom_point() +
geom_label(aes(label = word), check_overlap = TRUE, vjust = 1, hjust = 0) +
xlab("# of reviews") +
ylab("Average Stars") + expand_limits(x = c(10,40))
summary_pos<- count_words %>%  group_by(word) %>%
summarize(reviews = n(),
uses = sum(n),
average_rat = mean(as.integer(rating))) %>% filter(reviews>50) %>% arrange(desc(average_rat))
head(summary_pos,15) %>% ggplot(aes(x=reviews,y=average_rat))+ geom_point() +
geom_label(aes(label = word), check_overlap = TRUE, vjust = 1, hjust = 0) +
xlab("# of reviews") +
ylab("Average Stars")
head(count_words)
#count number of times word used in each review
count_words <- rdf_tidy %>%
count(review_num, rating, word) %>%
ungroup()
#returns most negative words
summary_neg<- count_words %>%  group_by(word) %>%
summarize(reviews = n(),
average_rat = mean(as.integer(rating))) %>% filter(reviews>10) %>% arrange(average_rat)
head(summary_neg,15) %>% ggplot(aes(x=reviews,y=average_rat))+ geom_point() +
geom_label(aes(label = word), check_overlap = TRUE, vjust = 1, hjust = 0) +
xlab("# of reviews") +
ylab("Average Rating") + expand_limits(x = c(10,40))
summary_pos<- count_words %>%  group_by(word) %>%
summarize(reviews = n(),
average_rat = mean(as.integer(rating))) %>% filter(reviews>50) %>% arrange(desc(average_rat))
head(summary_pos,15) %>% ggplot(aes(x=reviews,y=average_rat))+ geom_point() +
geom_label(aes(label = word), check_overlap = TRUE, vjust = 1, hjust = 0) +
xlab("# of reviews") +
ylab("Average Rating")
library(blogdown)
serve_site()
serve_site()
serve_site()
install.packages('learnr')
library(learnr)
install.packages("swirl")
library(swirl)
ls
ls()
