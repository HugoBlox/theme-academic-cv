max_features<-1000
#increase length of review considered
x_train_small <- pad_sequences(text_seqs, maxlen = 100)
model <- keras_model_sequential() %>%
#embedding layer
layer_embedding(input_dim = max_features, output_dim =embedding_dims, input_length = maxlen) %>%
layer_dropout(0.2) %>%
layer_conv_1d(
filters, kernel_size,
padding = "valid", activation = "relu", strides = 1
) %>%
layer_global_max_pooling_1d() %>%
layer_dense(units=hidden_dims, activation = "relu") %>%
layer_dropout(0.2) %>%
layer_dense(units=1,activation = "sigmoid")
model %>% compile(
loss = "binary_crossentropy",
optimizer = "adam",
metrics = "accuracy"
)
#increase num words for embedding
max_features<-5000
#increase length of review considered
x_train_small <- pad_sequences(text_seqs, maxlen = 400)
model <- keras_model_sequential() %>%
#embedding layer
layer_embedding(input_dim = max_features, output_dim =embedding_dims, input_length = maxlen) %>%
layer_dropout(0.2) %>%
layer_conv_1d(
filters, kernel_size,
padding = "valid", activation = "relu", strides = 1
) %>%
layer_global_max_pooling_1d() %>%
layer_dense(units=hidden_dims, activation = "relu") %>%
layer_dropout(0.2) %>%
layer_dense(units=1,activation = "sigmoid")
model %>% compile(
loss = "binary_crossentropy",
optimizer = "adam",
metrics = "accuracy"
)
hist <- model %>%
fit(
x_train_small,
y_train,
batch_size = 32,
epochs = 10,
validation_split = 0.2
)
#increase num words for embedding
max_features<-5000
maxlen<-400
#increase length of review considered
x_train_small <- pad_sequences(text_seqs, maxlen = maxlen)
model <- keras_model_sequential() %>%
#embedding layer
layer_embedding(input_dim = max_features, output_dim =embedding_dims, input_length = maxlen) %>%
layer_dropout(0.2) %>%
layer_conv_1d(
filters, kernel_size,
padding = "valid", activation = "relu", strides = 1
) %>%
layer_global_max_pooling_1d() %>%
layer_dense(units=hidden_dims, activation = "relu") %>%
layer_dropout(0.2) %>%
layer_dense(units=1,activation = "sigmoid")
model %>% compile(
loss = "binary_crossentropy",
optimizer = "adam",
metrics = "accuracy"
)
hist <- model %>%
fit(
x_train_small,
y_train,
batch_size = 32,
epochs = 10,
validation_split = 0.2
)
str(hist)
plot(hist)
#increase num words for embedding
max_features<-5000
maxlen<-400
#increase length of review considered
x_train_small <- pad_sequences(text_seqs, maxlen = maxlen)
model <- keras_model_sequential() %>%
#embedding layer
layer_embedding(input_dim = max_features, output_dim =embedding_dims, input_length = maxlen) %>%
layer_dropout(0.2) %>%
layer_conv_1d(
filters, kernel_size,
padding = "valid", activation = "relu", strides = 1
) %>%
layer_global_max_pooling_1d() %>%
layer_dense(units=hidden_dims, activation = "relu") %>%
layer_dropout(0.2) %>%
layer_dense(units=1,activation = "sigmoid")
model %>% compile(
loss = "binary_crossentropy",
optimizer = "adam",
metrics = "accuracy"
)
hist <- model %>%
fit(
x_train_small,
y_train,
batch_size = 32,
epochs = 10,
validation_split = 0.2
)
str(hist)
plot(hist)
library(blogdown)
serve_site()
library(tidyverse)
library(zoo)
library(knitr)
library(tidytext)
library(SnowballC)
library(keras)
library(kableExtra)
#load data
rdf<-readRDS("first_3000.Rda")
str(rdf)
#rename & change variable type
rdf <- rdf %>% rename(stay_date = id_date,
review = reviews) %>%
mutate_at(vars(stay_date, review),
~ as.character(.)) %>%
mutate(rating = as.factor(rating))
#change stay_date variable from character to date type
rdf$stay_date <- gsub("Date of stay: ", "", rdf$stay_date)
rdf$stay_date <- as.yearmon(rdf$stay_date, "%b %Y")
kable(head(rdf,3)) %>% kable_styling(bootstrap_options = "striped", full_width = F,font_size = 8)
#set seed
set.seed(42)
#shuffle dataframe
rows <- sample(nrow(rdf))
rdf <- rdf[rows, ]
rdf_bin <- rdf %>% mutate(review_num = row_number()) %>%
mutate(five_star = case_when(rating != 5 ~ 0, TRUE ~ 1)) %>% select(-rating, -stay_date)
rdf_bin %>% ggplot(aes(x = five_star)) +
geom_bar(aes(y = ..prop.., fill = factor(..x..)), stat = "count") +
scale_y_continuous(labels = scales::percent) + ylab("percent") +
scale_x_discrete()
# get text of review
text<-rdf_bin$review
max_features <- 1000
tokenizer <- text_tokenizer(num_words = max_features)
#fit tokenizer to actual reviews
tokenizer %>%
fit_text_tokenizer(text)
#num reviews
print(tokenizer$document_count)
#list of integers for reviews
text_seqs<- texts_to_sequences(tokenizer, text)
#cut reviews off after 100 words
maxlen <- 100
#define train data
x_train <- pad_sequences(text_seqs, maxlen = maxlen)
dim(x_train)
y_train <- rdf_bin$five_star
length(y_train)
# Network parameters
embedding_dims <- 50
filters <- 64
kernel_size <- 5
hidden_dims <- 50
epochs <- 10
#increase num words for embedding
max_features<-5000
maxlen<-400
#increase length of review considered
x_train_long <- pad_sequences(text_seqs, maxlen = maxlen)
model <- keras_model_sequential() %>%
#embedding layer
layer_embedding(input_dim = max_features, output_dim =embedding_dims, input_length = maxlen) %>%
layer_dropout(0.2) %>%
layer_conv_1d(
filters, kernel_size,
padding = "valid", activation = "relu", strides = 1
) %>%
layer_global_max_pooling_1d() %>%
layer_dense(units=hidden_dims, activation = "relu") %>%
layer_dropout(0.2) %>%
layer_dense(units=1,activation = "sigmoid")
model %>% compile(
loss = "binary_crossentropy",
optimizer = "rmsprop",
metrics = "accuracy"
)
hist <- model %>%
fit(
x_train_long,
y_train,
batch_size = 32,
epochs = 10,
validation_split = 0.2
)
str(hist)
plot(hist)
print(hist)
hist <- model %>%
fit(
x_train,
y_train,
batch_size = 32,
epochs = 10,
validation_split = 0.2
)
# get text of review
text<-rdf_bin$review
max_features <- 1000
tokenizer <- text_tokenizer(num_words = max_features)
#fit tokenizer to actual reviews
tokenizer %>%
fit_text_tokenizer(text)
#num reviews
print(tokenizer$document_count)
#list of integers for reviews
text_seqs<- texts_to_sequences(tokenizer, text)
#cut reviews off after 100 words
maxlen <- 100
#define train data
x_train <- pad_sequences(text_seqs, maxlen = maxlen)
dim(x_train)
y_train <- rdf_bin$five_star
length(y_train)
# Network parameters
embedding_dims <- 50
filters <- 64
kernel_size <- 5
hidden_dims <- 50
epochs <- 10
#input max_feat (total vocabulary count used for reviews:1000)
model <- keras_model_sequential() %>%
#embedding layer
layer_embedding(input_dim = max_features, output_dim =embedding_dims, input_length = maxlen) %>%
layer_dropout(0.2) %>%
layer_conv_1d(
filters, kernel_size,
padding = "valid", activation = "relu", strides = 1
) %>%
layer_global_max_pooling_1d() %>%
layer_dense(units=hidden_dims, activation = "relu") %>%
layer_dropout(0.2) %>%
layer_dense(units=1,activation = "sigmoid")
model %>% summary()
model %>% compile(
loss = "binary_crossentropy",
optimizer = "rmsprop",
metrics = "accuracy"
)
hist <- model %>%
fit(
x_train,
y_train,
batch_size = 32,
epochs = 10,
validation_split = 0.2
)
print(hist)
plot(hist)
#increase num words for embedding
max_features<-5000
maxlen<-400
#increase length of review considered
x_train_long <- pad_sequences(text_seqs, maxlen = maxlen)
model <- keras_model_sequential() %>%
#embedding layer
layer_embedding(input_dim = max_features, output_dim =embedding_dims, input_length = maxlen) %>%
layer_dropout(0.2) %>%
layer_conv_1d(
filters, kernel_size,
padding = "valid", activation = "relu", strides = 1
) %>%
layer_global_max_pooling_1d() %>%
layer_dense(units=hidden_dims, activation = "relu") %>%
layer_dropout(0.2) %>%
layer_dense(units=1,activation = "sigmoid")
model %>% compile(
loss = "binary_crossentropy",
optimizer = "rmsprop",
metrics = "accuracy"
)
hist <- model %>%
fit(
x_train_long,
y_train,
batch_size = 32,
epochs = 10,
validation_split = 0.2
)
print(hist)
plot(hist)
library(blogdown)
serve_site()
install.packages('data.table')
?fread
?fread()
getwd()
orders <- fread('../instacart/orders.csv',stringsAsFactors=TRUE)
library(data.table)
install.packages("data.table")
install.packages("data.table", type = "source",
repos = "http://Rdatatable.github.io/data.table")
install.packages("data.table", repos="https://Rdatatable.github.io/data.table")
getwd()
getwd()
library(blogdown)
serve_site()
new_post()
blogdown:::new_post_addin()
library(tidyverse)
library(ggthemes)
library(tidytext)
library(purrr)
library(stats)
library(corrr)
library(RColorBrewer)
food<-read_csv("fastfood_calories.csv")
food<-read_csv("fastfood_calories.csv")
library(tidyverse)
library(ggthemes)
library(tidytext)
library(purrr)
library(stats)
library(corrr)
library(RColorBrewer)
food<-read_csv("fastfood_calories.csv")
library(tidyverse)
library(ggthemes)
library(tidytext)
library(purrr)
library(stats)
library(corrr)
library(RColorBrewer)
food<-read_csv("fastfood_calories.csv")
food<-read_csv("fastfood_calories.csv")
head(food)
levels(as.factor(food$salad))
#All salad levels are "Other." This column can be removed.
food$salad<-NULL
food$X1<-NULL
#convert restaraunt to factor
food$restaurant<-as.factor(food$restaurant)
levels(food$restaurant)
library(blogdown)
serve_site()
serve_site()
blogdown:::new_post_addin()
library(rvest)
library(unpivotr)
install.packages("unpivotr")
install.packages("htmltools")
install.packages("htmltools")
library(rvest)
library(unpivotr)
library(htmltools)
library(tidyverse)
?as_cells
library(rvest)
library(unpivotr)
library(htmltools)
library(tidyverse)
#read in html data
link<-"https://www.dvcrequest.com/point-chart/bay_lake_towers_2020.html"
hlink<- read_html(link)
table<-hlink %>% html_nodes("table") %>%
html_table(header=F,fill=T)
table <- table[[1]]
#add the table to a dataframe,
dict <- as.data.frame(table)
cells <- as_cells(table)
cells<-cells %>% filter(col>2,row>1) %>% select(-data_type)
cells %>% head()
cells %>% spread(row,chr)
cells %>% head(10)
cellstemp<-
cells %>% spread(row,chr) %>% filter(!col %in% c('6','10','14'))
room_view<-cellstemp[,2:3]
#seasons
adventure<-cellstemp[,4:6]
choice<-cellstemp[,7:9]
dream<-cellstemp[,10:12]
magic<-cellstemp[,13:15]
premier<-cellstemp[,16:18]
adventure<-cbind(room_view,adventure)
choice<-cbind(room_view,choice)
dream<-cbind(room_view,dream)
magic<-cbind(room_view,magic)
premier<-cbind(room_view,premier)
dfs<-data.frame(Map(c,adventure,choice,dream,magic,premier))
dfs %>% head()
dfs<-dfs %>% rename_at(c(1,2,3,4,5),~c("room","view","season","Sun_Th","Fri_Sat")) %>%
mutate_at(vars('Sun_Th','Fri_Sat'),as.character) %>%
mutate_at(vars('Sun_Th','Fri_Sat'),as.numeric)
dfl<-dfs %>% gather("weekday", "points",Sun_Th:Fri_Sat)
dfl$room<-as.character(dfl$room)
head(dfl)
#change naming of room type
dfl[dfl$room == "STUDIO(Sleeps up to 4)","room"] = "Studio"
dfl[dfl$room == "1-BEDROOM\r\n      VACATION HOME(Sleeps up to 5)","room"] = "1-Bedroom"
dfl[dfl$room == "2-BEDROOM\r\n      VACATION HOME(Sleeps up to 9)","room"] = "2-Bedroom"
dfl[dfl$room == "3-BEDROOM\r\n  GRAND VILLA(Sleeps up to 12)","room"] = "3-Bedroom"
head(dfl)
dfl %>%
ggplot(aes(x=fct_reorder(room,points),y=points,fill=fct_reorder(view,points)))+geom_boxplot()+scale_fill_brewer(palette= "OrRd")
dfl %>%
ggplot(aes(x=fct_reorder(room,points),y=points,fill=fct_reorder(view,points)))+
geom_boxplot()+
scale_fill_brewer(palette= "OrRd")+
theme(legend.title = "View")
dfl %>%
ggplot(aes(x=fct_reorder(room,points),y=points,fill=fct_reorder(view,points)))+
geom_boxplot()+
scale_fill_brewer(palette= "OrRd")+
theme(legend.title = element_text("View"))
dfl %>%
ggplot(aes(x=fct_reorder(room,points),y=points,fill=fct_reorder(view,points)))+
geom_boxplot()+
scale_fill_brewer(palette= "OrRd")+
xlab("")
dfl %>%
ggplot(aes(x=fct_reorder(room,points),y=points,fill=fct_reorder(view,points)))+
geom_boxplot()+
scale_fill_brewer(palette= "OrRd")+
labs(x="",fill="View")
install.packages("plotly")
install.packages("plotly")
library(plotly)
library(blogdown)
serve_site()
serve_site()
library(rvest)
library(unpivotr)
library(htmltools)
library(tidyverse)
library(kableExtra)
#read in html data
link<-"https://www.dvcrequest.com/point-chart/bay_lake_towers_2020.html"
hlink<- read_html(link)
table<-hlink %>% html_nodes("table") %>%
html_table(header=F,fill=T)
table <- table[[1]]
#add the table to a dataframe,
dict <- as.data.frame(table)
cells <- as_cells(table)
cells<-cells %>% filter(col>2,row>1) %>% select(-data_type)
cells %>% head(10) %>% kable()
library(blogdown)
serve_site()
library(rvest)
library(unpivotr)
library(htmltools)
library(tidyverse)
library(kableExtra)
#read in html data
link<-"https://www.dvcrequest.com/point-chart/bay_lake_towers_2020.html"
hlink<- read_html(link)
table<-hlink %>% html_nodes("table") %>%
html_table(header=F,fill=T)
table <- table[[1]]
#add the table to a dataframe,
dict <- as.data.frame(table)
cells <- as_cells(table)
cells<-cells %>% filter(col>2,row>1) %>% select(-data_type)
cells %>% head() %>% kable()
cellstemp<-
cells %>% spread(row,chr) %>% filter(!col %in% c('6','10','14'))
room_view<-cellstemp[,2:3]
#seasons
adventure<-cellstemp[,4:6]
choice<-cellstemp[,7:9]
dream<-cellstemp[,10:12]
magic<-cellstemp[,13:15]
premier<-cellstemp[,16:18]
adventure<-cbind(room_view,adventure)
choice<-cbind(room_view,choice)
dream<-cbind(room_view,dream)
magic<-cbind(room_view,magic)
premier<-cbind(room_view,premier)
dfs<-data.frame(Map(c,adventure,choice,dream,magic,premier))
dfs %>% head() %>% kable()
?kable
blogdown:::new_post_addin()
avg_points<-comp %>%
filter(room != "3-Bedroom") %>%
group_by(season,room,resort) %>% summarise(avg_point=mean(points))
library(tidyverse)
library(lubridate)
library(plotly)
install.packages("plotly")
install.packages("plotly")
library(tidyverse)
library(lubridate)
library(plotly)
bc<-readRDS("BC2020.rds")
library(tidyverse)
library(lubridate)
library(plotly)
bc<-readRDS("BC2020.rds")
library(tidyverse)
library(lubridate)
library(plotly)
bc<-readRDS("BC2020.rds")
BC2020 <- readRDS("~/mysite/content/post/BC2020.rds")
library(tidyverse)
library(lubridate)
library(plotly)
bc<-readRDS("BC2020.rds")
